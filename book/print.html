<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Shadow Simulator</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        
        <link rel="stylesheet" href="css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="index.html">Introduction</a></li><li class="chapter-item expanded affix "><li class="part-title">Shadow Network Simulator</li><li class="chapter-item expanded "><div><strong aria-hidden="true">1.</strong> Installation and Setup</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="shadow/supported_platforms.html"><strong aria-hidden="true">1.1.</strong> Supported Platforms</a></li><li class="chapter-item expanded "><a href="shadow/install_dependencies.html"><strong aria-hidden="true">1.2.</strong> Dependencies</a></li><li class="chapter-item expanded "><a href="shadow/install_shadow.html"><strong aria-hidden="true">1.3.</strong> Shadow</a></li><li class="chapter-item expanded "><a href="shadow/system_configuration.html"><strong aria-hidden="true">1.4.</strong> System Configuration</a></li><li class="chapter-item expanded "><a href="shadow/install_shadow_with_docker.html"><strong aria-hidden="true">1.5.</strong> (Experimental) Shadow with Docker</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">2.</strong> The Shadow Simulator</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="shadow/getting_started.html"><strong aria-hidden="true">2.1.</strong> Getting Started</a></li><li class="chapter-item expanded "><a href="shadow/parsing_statistics.html"><strong aria-hidden="true">2.2.</strong> Parsing Statistics</a></li><li class="chapter-item expanded "><a href="shadow/log_format.html"><strong aria-hidden="true">2.3.</strong> Log Format</a></li><li class="chapter-item expanded "><a href="shadow/design_overview.html"><strong aria-hidden="true">2.4.</strong> Design Overview</a></li><li class="chapter-item expanded "><a href="shadow/notes_and_faq.html"><strong aria-hidden="true">2.5.</strong> Notes and FAQs</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">3.</strong> Simulation Customization</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="shadow/shadow_config.html"><strong aria-hidden="true">3.1.</strong> Shadow Configuration</a></li><li class="chapter-item expanded "><a href="shadow/network_config.html"><strong aria-hidden="true">3.2.</strong> Network Configuration</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="shadow/network_graph_attributes.html"><strong aria-hidden="true">3.2.1.</strong> Graph Configuration</a></li></ol></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">4.</strong> Developer Guides</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="shadow/developer_guide.html"><strong aria-hidden="true">4.1.</strong> Debugging and Profiling</a></li><li class="chapter-item expanded "><a href="shadow/ci.html"><strong aria-hidden="true">4.2.</strong> Continous Integration Tests</a></li><li class="chapter-item expanded "><a href="shadow/using_recompiled_libc.html"><strong aria-hidden="true">4.3.</strong> Using a Recompiled Libc</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">5.</strong> The Shadow Project</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="shadow/contributing.html"><strong aria-hidden="true">5.1.</strong> Contributing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="shadow/coding_style.html"><strong aria-hidden="true">5.1.1.</strong> Coding Style</a></li><li class="chapter-item expanded "><a href="shadow/pull_requests.html"><strong aria-hidden="true">5.1.2.</strong> Pull Requests</a></li></ol></li><li class="chapter-item expanded "><a href="shadow/maintainer_playbook.html"><strong aria-hidden="true">5.2.</strong> Maintainer Playbook</a></li><li class="chapter-item expanded "><a href="shadow/nsf_sponsorship.html"><strong aria-hidden="true">5.3.</strong> NSF Sponsorship</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">TGen Traffic Generator</li><li class="chapter-item expanded "><a href="tgen/index.html"><strong aria-hidden="true">6.</strong> About</a></li><li class="chapter-item expanded "><a href="tgen/TGen-Markov-Models.html"><strong aria-hidden="true">7.</strong> Markov Models</a></li><li class="chapter-item expanded "><a href="tgen/TGen-Options.html"><strong aria-hidden="true">8.</strong> Options</a></li><li class="chapter-item expanded "><a href="tgen/TGen-Overview.html"><strong aria-hidden="true">9.</strong> Overview</a></li><li class="chapter-item expanded "><a href="tgen/Tools-JSON-Format.html"><strong aria-hidden="true">10.</strong> JSON Format</a></li><li class="chapter-item expanded affix "><li class="part-title">Tor Network Simulation</li><li class="chapter-item expanded "><a href="tornettools/index.html"><strong aria-hidden="true">11.</strong> TorNetTools</a></li><li class="chapter-item expanded "><a href="oniontrace/index.html"><strong aria-hidden="true">12.</strong> OnionTrace</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">Shadow Simulator</h1>

                    <div class="right-buttons">
                        
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                        <a href="https://github.com/shadow" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        
                        

                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="supported-platforms"><a class="header" href="#supported-platforms">Supported Platforms</a></h2>
<p>Shadow officially supports the following platforms:</p>
<ul>
<li>Ubuntu 18.04 and 20.04</li>
<li>Debian 10</li>
<li>Fedora 33</li>
<li>CentOS 7 and 8</li>
</ul>
<p>If you are installing Shadow within a Docker container, you must increase the size of the container's <code>/dev/shm</code> mount by passing <code>--shm-size=&quot;1g&quot;</code> (with a suitable size for your system and experiments) to <code>docker run</code>.</p>
<p>If you are having difficulty installing Shadow on any of these platforms, you may find the <a href="https://github.com/shadow/shadow/blob/main/.github/workflows/run_tests.yml">continuous integration build steps</a> helpful.</p>
<p>We do not provide official support for other platforms. This means that we do not ensure that Shadow successfully builds and passes tests on other platforms. However, we will review pull requests that allow Shadow to build and run on unsupported platforms.</p>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="installing-dependencies"><a class="header" href="#installing-dependencies">Installing Dependencies</a></h2>
<h4 id="required"><a class="header" href="#required">Required:</a></h4>
<ul>
<li>gcc, gcc-c++ (or clang, clang++)</li>
<li>python (version &gt;= 3.6)</li>
<li>glib (version &gt;= 2.32.0)</li>
<li>igraph (version &gt;= 0.5.4)</li>
<li>cmake (version &gt;= 3.2)</li>
<li>make</li>
<li>xz-utils</li>
<li>procps</li>
<li>cargo, rustc (version ~ latest)</li>
</ul>
<h4 id="recommended-python-modules-for-helperanalysis-scripts"><a class="header" href="#recommended-python-modules-for-helperanalysis-scripts">Recommended Python Modules (for helper/analysis scripts):</a></h4>
<ul>
<li>numpy, scipy, matplotlib, networkx, lxml, pyyaml</li>
</ul>
<h4 id="recommended-system-tools"><a class="header" href="#recommended-system-tools">Recommended System Tools:</a></h4>
<ul>
<li>git, dstat, screen, htop</li>
</ul>
<h3 id="apt-debianubuntu"><a class="header" href="#apt-debianubuntu">APT (Debian/Ubuntu):</a></h3>
<pre><code class="language-bash">sudo apt-get install -y \
    cmake \
    findutils \
    libc-dbg \
    libglib2.0-0 \
    libglib2.0-dev \
    libigraph0-dev \
    libigraph0v5 \
    libprocps-dev \
    make \
    python3 \
    python3-pip \
    xz-utils \
    gcc \
    g++

# rustup: https://rustup.rs
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Optional dependencies

sudo apt-get install -y \
    python3-numpy \
    python3-lxml \
    python3-matplotlib \
    python3-networkx \
    python3-scipy \
    python3-yaml

sudo apt-get install -y \
    dstat \
    git \
    htop \
    screen
</code></pre>
<h3 id="yum-fedoracentos"><a class="header" href="#yum-fedoracentos">YUM (Fedora/CentOS):</a></h3>
<p>In more recent versions of Fedora and CentOS, <code>yum</code> can be exchanged for <code>dnf</code> in these commands.
Before running these commands, please check any platform-specific requirements below.</p>
<p><strong>Warning:</strong> <code>yum</code> and <code>dnf</code> often install 32-bit (<code>i686</code>) versions of libraries. You may want to use the <code>--best</code> option to make sure you're installing the 64-bit (<code>x86_64</code>) versions, which are required by Shadow.</p>
<pre><code class="language-bash">sudo yum install -y \
    cmake \
    findutils \
    glib2 \
    glib2-devel \
    igraph \
    igraph-devel \
    make \
    procps-devel \
    python3 \
    python3-pip \
    xz \
    xz-devel \
    yum-utils \
    diffutils \
    gcc \
    gcc-c++

# rustup: https://rustup.rs
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Optional dependencies

sudo yum install -y \
    python3-numpy \
    python3-lxml \
    python3-matplotlib \
    python3-networkx \
    python3-scipy \
    python3-yaml

sudo yum install -y \
    dstat \
    git \
    htop \
    screen
</code></pre>
<h4 id="centos-7"><a class="header" href="#centos-7">CentOS 7</a></h4>
<p>You must enable the EPEL repository using:</p>
<pre><code class="language-bash">yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
</code></pre>
<p>Instead of installing <code>cmake</code>, you should instead install <code>cmake3</code>:</p>
<pre><code class="language-bash">yum install -y cmake3
alternatives --install /usr/local/bin/cmake cmake /usr/bin/cmake3 20 \
    --slave /usr/local/bin/ctest ctest /usr/bin/ctest3 \
    --slave /usr/local/bin/cpack cpack /usr/bin/cpack3 \
    --slave /usr/local/bin/ccmake ccmake /usr/bin/ccmake3 \
    --family cmake
</code></pre>
<h4 id="centos-8"><a class="header" href="#centos-8">CentOS 8</a></h4>
<p>As procps-ng-devel, igraph, and igraph-devel are not available on CentOS 8, you must install them manually.</p>
<pre><code class="language-bash">dnf remove -y procps-ng procps-ng-devel
dnf install -y http://vault.centos.org/centos/7.7.1908/os/x86_64/Packages/procps-ng-3.3.10-26.el7.x86_64.rpm
dnf install -y http://vault.centos.org/centos/7.7.1908/os/x86_64/Packages/procps-ng-devel-3.3.10-26.el7.x86_64.rpm
dnf install -y https://dl.fedoraproject.org/pub/archive/epel/7.7/x86_64/Packages/i/igraph-0.7.1-12.el7.x86_64.rpm
dnf install -y https://dl.fedoraproject.org/pub/archive/epel/7.7/x86_64/Packages/i/igraph-devel-0.7.1-12.el7.x86_64.rpm
</code></pre>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="shadow-setup"><a class="header" href="#shadow-setup">Shadow Setup</a></h2>
<pre><code class="language-bash">git clone https://github.com/shadow/shadow.git
cd shadow
./setup build --clean --test
./setup test
./setup install
</code></pre>
<p>You should add <code>/home/${USER}/.shadow/bin</code> to your shell setup for the PATH environment variable (e.g., in <code>~/.bashrc</code> or <code>~/.bash_profile</code>).</p>
<pre><code class="language-bash">echo 'export PATH=&quot;${PATH}:/home/${USER}/.shadow/bin&quot;' &gt;&gt; ~/.bashrc &amp;&amp; source ~/.bashrc
</code></pre>
<p>Check that Shadow is installed and runs:</p>
<pre><code class="language-bash">shadow --version
shadow --help
</code></pre>
<h4 id="setup-notes"><a class="header" href="#setup-notes">Setup Notes</a></h4>
<ul>
<li>
<p>All build output is generated out-of-source, by default to the <code>./build</code> directory.</p>
</li>
<li>
<p>Use <code>./setup build --help</code> to see all build options; the most useful build options are:</p>
<ul>
<li><code>-g</code> or <code>--debug</code> to build Shadow with debugging symbols</li>
<li><code>--include</code> and <code>--library</code> if you installed any dependencies in non-standard locations or somewhere other than <code>~/.shadow</code>.</li>
<li><code>--prefix</code> if you want to install Shadow somewhere besides <code>~/.shadow</code></li>
</ul>
</li>
<li>
<p>The <code>setup</code> script is a wrapper to <code>cmake</code> and <code>make</code>. Using <code>cmake</code> and <code>make</code> directly is also possible, but strongly discouraged. For example:</p>
<pre><code class="language-bash"># alternative installation method
rm -r build &amp;&amp; mkdir build &amp;&amp; cd build
cmake -DCMAKE_INSTALL_PREFIX=&quot;~/.shadow&quot; -DSHADOW_TEST=ON ..
make
ctest
make install
</code></pre>
</li>
</ul>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="system-configs-and-limits"><a class="header" href="#system-configs-and-limits">System Configs and Limits</a></h2>
<p>Some Linux system configuration changes are needed to run large-scale Shadow simulations (more than about 1000 nodes).</p>
<h4 id="number-of-open-files"><a class="header" href="#number-of-open-files">Number of Open Files</a></h4>
<p>There is a default linux system limit on the number of open files. If each node 
in your Shadow plug-in opens many file or socket descriptors (if you have many nodes, this is very likely to happen), you'll likely want to increase the limit so you application doesn't start getting errors when calling <code>open()</code> or <code>socket()</code>.</p>
<h6 id="system-wide-limits"><a class="header" href="#system-wide-limits">System-wide Limits</a></h6>
<p>Check the <em>system-wide</em> limits with:</p>
<pre><code class="language-bash">sysctl fs.nr_open # per-process open file limit
sysctl fs.file-max # system-wide open file limit
</code></pre>
<p>Use <code>cat /proc/sys/fs/file-nr</code> to find:</p>
<ol>
<li>the current, system-wide number of used file handles</li>
<li>the current, system-wide number of free file handles</li>
<li>and the system-wide limit on the maximum number of open files for all processes</li>
</ol>
<p>Change the limits, persistent across reboots, and apply now:</p>
<pre><code class="language-bash">sysctl -w fs.nr_open=10485760
echo &quot;fs.nr_open = 10485760&quot; &gt;&gt; /etc/sysctl.conf
sysctl -w fs.file-max=10485760
echo &quot;fs.file-max = 10485760&quot; &gt;&gt; /etc/sysctl.conf
sysctl -p
</code></pre>
<h6 id="user-limits"><a class="header" href="#user-limits">User Limits</a></h6>
<p>Check the maximum number of open file descriptors <em>currently allowed</em> in your session:</p>
<pre><code class="language-bash">ulimit -n
</code></pre>
<p>Check the number of files <em>currently used</em> in a process with pid=PID:</p>
<pre><code class="language-bash">/bin/ls -l /proc/PID/fd/ | wc -l
</code></pre>
<p>You will want to almost certainly want to raise the user file limit by modifying <code>/etc/security/limits.conf</code>. For example:</p>
<pre><code>rjansen soft nofile 10485760
rjansen hard nofile 10485760
</code></pre>
<p>The max you can use is your <code>fs.nr_open</code> system-wide limit setting from above. You need to either log out and back in or reboot for the changes to take affect. You can watch <code>/proc/sys/fs/file-nr</code> and reduce the limit according to your usage, if you'd like.</p>
<h4 id="number-of-maps"><a class="header" href="#number-of-maps">Number of Maps</a></h4>
<p>There is a system limit on the number of <code>mmap()</code> mappings per process. Most users will not have to modify these settings. However, if an application running in Shadow makes extensive use of <code>mmap()</code>, you may need to increase the limit.</p>
<h6 id="process-limit"><a class="header" href="#process-limit">Process Limit</a></h6>
<p>The process limit can be queried in these ways:</p>
<pre><code class="language-bash">sysctl vm.max_map_count
cat /proc/sys/vm/max_map_count
</code></pre>
<p>You can check the number of maps currently used in a process with pid=PID like this:</p>
<pre><code class="language-bash">wc -l /proc/PID/maps
</code></pre>
<p>Set a new limit, make it persistent, apply it now:</p>
<pre><code class="language-bash">sudo sysctl -w vm.max_map_count=1073741824
sudo echo &quot;vm.max_map_count = 1073741824&quot; &gt;&gt; /etc/sysctl.conf
sudo sysctl -p
</code></pre>
<h4 id="for-more-information"><a class="header" href="#for-more-information">For more information</a></h4>
<p>https://www.kernel.org/doc/Documentation/sysctl/fs.txt<br />
https://www.kernel.org/doc/Documentation/sysctl/vm.txt</p>
<pre><code class="language-bash">man proc
man ulimit
cat /proc/sys/fs/file-max
cat /proc/sys/fs/inode-max
</code></pre>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="run-from-the-dockerfile"><a class="header" href="#run-from-the-dockerfile">Run from the Dockerfile</a></h2>
<ol>
<li>Install docker from https://docs.docker.com/engine/install/.</li>
<li>Build container:</li>
</ol>
<pre><code>git clone https://github.com/shadow/shadow.git
cd shadow
docker build . -t shadow --shm-size=&quot;1g&quot;
</code></pre>
<ol start="3">
<li>Run tests:</li>
</ol>
<pre><code>docker run --shm-size=&quot;1g&quot; --privileged --rm --entrypoint /src/ci/container_scripts/test.sh shadow
</code></pre>
<h2 id="run-a-simulation"><a class="header" href="#run-a-simulation">Run a simulation</a></h2>
<p>To be able to run a simulation you have to mount a volume with the simulation dependencies (configurations and binaries). This will generate a log directory owned by <code>root</code>.</p>
<p>For example, the next command runs the <code>shadow.config.xml</code> simulation present in the current path:</p>
<pre><code>docker run --shm-size=&quot;1g&quot; --privileged --rm --log-driver=none -v $(pwd):/src/ shadow --interpose-method=ptrace -l debug shadow.config.xml
</code></pre>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h1 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h1>
<p>When installing Shadow, the main executable was placed in <code>/bin</code> in your install prefix (<code>~/.shadow/bin</code> by default). As a reminder, it would be helpful if this location was included in your environment <code>PATH</code>.</p>
<p>The main Shadow binary executable, <code>shadow</code>, contains most of the simulator's code, including events and the event engine, the network stack, and the routing logic. Shadow's event engine supports multi-threading using the <code>-p</code> or <code>--parallelism</code> flags (or their corresponding <a href="shadow/shadow_config.html#generalparallelism">configuration file option</a>) to simulate multiple hosts in parallel.</p>
<p>Shadow can typically run applications without modification, but there are a few limitations to be aware of:</p>
<ul>
<li>Applications must not fork or exec</li>
<li>Applications should not use or expect signals</li>
<li>Shadow does not support IPv6</li>
</ul>
<h2 id="example-http-server"><a class="header" href="#example-http-server">Example HTTP Server</a></h2>
<p>The following example simulates the network traffic of an HTTP server with 3 clients, each running on different virtual hosts. If you do not have Python or cURL installed, you can download them through your distribution's package manager.</p>
<p>Each client uses cURL to make an HTTP request to a basic Python HTTP server.</p>
<p><code>server.py</code>:</p>
<pre><code class="language-python">import http.server

httpd = http.server.HTTPServer(('', 80), http.server.SimpleHTTPRequestHandler)
httpd.serve_forever()
</code></pre>
<p>Shadow requires a configuration file that specifies information about the network topology and the processes to run within the simulation. This example uses a built-in network graph for simplicity. Write this configuration file to the same directory as the <code>server.py</code> Python script above.</p>
<p><code>shadow.yaml</code>:</p>
<pre><code class="language-yaml">general:
  # stop after 10 simulated seconds
  stop_time: 10

network:
  graph:
    # use a built-in network graph containing
    # a single vertex with a bandwidth of 1 Gbit
    type: 1_gbit_switch

hosts:
  # a host with the hostname 'server'
  server:
    processes:
    - path: /bin/python3
      args: ../../../server.py
      start_time: 3
  # three hosts with hostnames 'client1', 'client2', and 'client3'
  client:
    quantity: 3
    processes:
    - path: /bin/curl
      args: -s server
      start_time: 5
</code></pre>
<p>Shadow stores simulation data to the <code>shadow.data</code> directory by default. We first remove this directory if it already exists, and then run Shadow.</p>
<pre><code class="language-bash"># delete any existing simulation data
rm -rf shadow.data
shadow shadow.yaml &gt; shadow.log
</code></pre>
<p>This small Shadow simulation should complete almost immediately.</p>
<h3 id="simulation-output"><a class="header" href="#simulation-output">Simulation Output</a></h3>
<p>Shadow will write simulation output to the <code>shadow.data</code> directory. Each host has its own directory under <code>shadow.data/hosts</code>. For example:</p>
<pre><code class="language-bash">$ ls -l shadow.data/hosts
drwxrwxr-x 2 user user 4096 Jun  2 16:54 client1
drwxrwxr-x 2 user user 4096 Jun  2 16:54 client2
drwxrwxr-x 2 user user 4096 Jun  2 16:54 client3
drwxrwxr-x 2 user user 4096 Jun  2 16:54 server
</code></pre>
<p>Each host directory contains the output for each process running on that host. For example:</p>
<pre><code class="language-bash">$ ls -l shadow.data/hosts/client1
-rw-rw-r-- 1 user user   1 Jun  2 16:54 client1.curl.1000.exitcode
-rw-rw-r-- 1 user user   0 Jun  2 16:54 client1.curl.1000.shimlog
-rw-r--r-- 1 user user   0 Jun  2 16:54 client1.curl.1000.stderr
-rw-r--r-- 1 user user 542 Jun  2 16:54 client1.curl.1000.stdout

$ cat shadow.data/hosts/client1/client1.curl.1000.stdout
&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01//EN&quot; &quot;http://www.w3.org/TR/html4/strict.dtd&quot;&gt;
&lt;html&gt;
&lt;head&gt;
&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot;&gt;
&lt;title&gt;Directory listing for /&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;Directory listing for /&lt;/h1&gt;
...
</code></pre>
<p>Each host directory is also the <a href="https://en.wikipedia.org/wiki/Working_directory">working directory</a> for the host's processes, which is why we specified <code>../../../server.py</code> as the path to the Python script in our Shadow configuration file (<code>./shadow.data/hosts/server/../../../server.py</code> → <code>./server.py</code>).</p>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h1 id="parsing-statistics"><a class="header" href="#parsing-statistics">Parsing Statistics</a></h1>
<p>Shadow logs simulator heartbeat messages that contain useful system information for each virtual node in the experiment. For example, Shadow logs the number of bytes sent/received, number of bytes allocated/deallocated, CPU usage, etc. You can parse these heartbeat log messages to get insight into the simulation. Details of these heartbeat messages can be found <a href="shadow/log_format.html#heartbeat-messages">here</a>.</p>
<h2 id="generating-traffic"><a class="header" href="#generating-traffic">Generating Traffic</a></h2>
<p>This example uses the <a href="https://github.com/shadow/tgen">TGen traffic generator</a> to generate network traffic between hosts, and then shows results from Shadow's heartbeat messages.</p>
<p>TGen is capable of modeling generic behaviors with an action-dependency graph in the standard GraphML format. If you don't have it installed, you can follow the <a href="https://github.com/shadow/tgen/#setup">instructions here</a>. The following example runs TGen with 10 clients that each download 10 files from a set of 5 servers over a simple network topology.</p>
<p><code>shadow.yaml</code>:</p>
<pre><code class="language-yaml">general:
  # stop after 1 simulated hour
  stop_time: 3600

network:
  graph:
    # use a built-in network graph containing
    # a single vertex with a bandwidth of 1 Gbit
    type: 1_gbit_switch

hosts:
  # a host with the hostname 'server'
  server:
    processes:
    - path: ~/.local/bin/tgen
      args: ../../../tgen.server.graphml.xml
      start_time: 1
  # a host with the hostname 'client'
  client:
    processes:
    - path: ~/.local/bin/tgen
      args: ../../../tgen.client.graphml.xml
      start_time: 2
</code></pre>
<p>TGen requires an action-dependency graph for the client and server. See the <a href="https://github.com/shadow/tgen/tree/main/doc">TGen documentation</a> for more information about customizing TGen behaviors.</p>
<p><code>tgen.server.graphml.xml</code>:</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;graphml xmlns=&quot;http://graphml.graphdrawing.org/xmlns&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd&quot;&gt;
  &lt;key attr.name=&quot;serverport&quot; attr.type=&quot;string&quot; for=&quot;node&quot; id=&quot;d1&quot; /&gt;
  &lt;key attr.name=&quot;loglevel&quot; attr.type=&quot;string&quot; for=&quot;node&quot; id=&quot;d0&quot; /&gt;
  &lt;graph edgedefault=&quot;directed&quot;&gt;
    &lt;node id=&quot;start&quot;&gt;
      &lt;data key=&quot;d0&quot;&gt;info&lt;/data&gt;
      &lt;data key=&quot;d1&quot;&gt;8888&lt;/data&gt;
    &lt;/node&gt;
  &lt;/graph&gt;
&lt;/graphml&gt;
</code></pre>
<p><code>tgen.client.graphml.xml</code>:</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;graphml xmlns=&quot;http://graphml.graphdrawing.org/xmlns&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd&quot;&gt;
  &lt;key attr.name=&quot;recvsize&quot; attr.type=&quot;string&quot; for=&quot;node&quot; id=&quot;d5&quot; /&gt;
  &lt;key attr.name=&quot;sendsize&quot; attr.type=&quot;string&quot; for=&quot;node&quot; id=&quot;d4&quot; /&gt;
  &lt;key attr.name=&quot;count&quot; attr.type=&quot;string&quot; for=&quot;node&quot; id=&quot;d3&quot; /&gt;
  &lt;key attr.name=&quot;time&quot; attr.type=&quot;string&quot; for=&quot;node&quot; id=&quot;d2&quot; /&gt;
  &lt;key attr.name=&quot;peers&quot; attr.type=&quot;string&quot; for=&quot;node&quot; id=&quot;d1&quot; /&gt;
  &lt;key attr.name=&quot;loglevel&quot; attr.type=&quot;string&quot; for=&quot;node&quot; id=&quot;d0&quot; /&gt;
  &lt;graph edgedefault=&quot;directed&quot;&gt;
    &lt;node id=&quot;start&quot;&gt;
      &lt;data key=&quot;d0&quot;&gt;info&lt;/data&gt;
      &lt;data key=&quot;d1&quot;&gt;server:8888&lt;/data&gt;
    &lt;/node&gt;
    &lt;node id=&quot;pause&quot;&gt;
      &lt;data key=&quot;d2&quot;&gt;1,2,3&lt;/data&gt;
    &lt;/node&gt;
    &lt;node id=&quot;end&quot;&gt;
      &lt;data key=&quot;d3&quot;&gt;100&lt;/data&gt;
    &lt;/node&gt;
    &lt;node id=&quot;stream&quot;&gt;
      &lt;data key=&quot;d4&quot;&gt;1 MiB&lt;/data&gt;
      &lt;data key=&quot;d5&quot;&gt;1 MiB&lt;/data&gt;
    &lt;/node&gt;
    &lt;edge source=&quot;start&quot; target=&quot;stream&quot; /&gt;
    &lt;edge source=&quot;pause&quot; target=&quot;start&quot; /&gt;
    &lt;edge source=&quot;end&quot; target=&quot;pause&quot; /&gt;
    &lt;edge source=&quot;stream&quot; target=&quot;end&quot; /&gt;
  &lt;/graph&gt;
&lt;/graphml&gt;
</code></pre>
<p>With those three files saved in the same directory, you can start a simulation. This example may take a few minutes.</p>
<pre><code class="language-bash"># delete any existing simulation data
rm -rf shadow.data
shadow shadow.yaml &gt; shadow.log
</code></pre>
<p>In the TGen process output, lines containing <code>stream-success</code> represent completed downloads and contain useful timing statistics. From these lines we should see that clients have completed a total of <strong>100</strong> streams:</p>
<pre><code class="language-bash">for d in shadow.data/hosts/client*; do grep &quot;stream-success&quot; ${d}/* ; done | tee clients.log | wc -l
</code></pre>
<p>We can also look at the transfers from the servers' perspective:</p>
<pre><code class="language-bash">for d in shadow.data/hosts/server*; do grep &quot;stream-success&quot; ${d}/* ; done | tee servers.log | wc -l
</code></pre>
<h2 id="parsing-and-plotting-results"><a class="header" href="#parsing-and-plotting-results">Parsing and Plotting Results</a></h2>
<p>Shadow includes some Python scripts that can parse important statistics from the Shadow log messages, including network throughput over time, client download statistics, and client load statistics, and then visualize the results. The following will parse and plot the output produced from the above experiment:</p>
<pre><code class="language-bash"># parse the shadow output file
src/tools/parse-shadow.py --help
src/tools/parse-shadow.py --prefix results shadow.log
# plot the results
src/tools/plot-shadow.py --help
src/tools/plot-shadow.py --data results &quot;example-plots&quot;
</code></pre>
<p>The <code>parse-*.py</code> scripts generate <code>stats.*.json.xz</code> files. The (heavily trimmed) contents of <code>stats.shadow.json</code> look like the following:</p>
<pre><code class="language-json">$ xzcat results/stats.shadow.json.xz
{
  &quot;nodes&quot;: {
    &quot;client:11.0.0.1&quot;: {
      &quot;recv&quot;: {
        &quot;bytes_control_header&quot;: {
          &quot;0&quot;: 0,
          &quot;1&quot;: 0,
          &quot;2&quot;: 0,
          ...
          &quot;3599&quot;: 0
        },
        &quot;bytes_control_header_retrans&quot;: { ... },
        &quot;bytes_data_header&quot;: { ... },
        &quot;bytes_data_header_retrans&quot;: { ... },
        &quot;bytes_data_payload&quot;: { ... },
        &quot;bytes_data_payload_retrans&quot;: { ... },
        &quot;bytes_total&quot;: { ... }
      },
      &quot;send&quot;: { ... }
    },
    &quot;server:11.0.0.2&quot;: { ... }
  },
  &quot;ticks&quot;: {
    &quot;2&quot;: {
      &quot;maxrss_gib&quot;: 0.162216,
      &quot;time_seconds&quot;: 0.070114
    },
    &quot;3&quot;: { ... },
    ...
    &quot;3599&quot;: { ... }
  }
}
</code></pre>
<p>The <code>plot-*.py</code> scripts generate graphs. Open the PDF file that was created to see the graphed results.</p>
<p>You can also parse and plot the TGen output using the <code>tgentools</code> program from the TGen repo. <a href="https://github.com/shadow/tgen/blob/main/doc/Tools-Setup.md">This page</a> describes how to get started.</p>
<h3 id="combining-simulation-data"><a class="header" href="#combining-simulation-data">Combining Simulation Data</a></h3>
<p>Consider a set of experiments where we would like to analyze the effect of changing our nodes' traffic queueing disciplines. We run the following 2 experiments:</p>
<pre><code class="language-bash"># delete any existing simulation data and post-processing
rm -rf shadow.data shadow.log qdisc-fifo.data qdisc-fifo.log qdisc-rr.data qdisc-rr.log
shadow --interface-qdisc fifo       --data-directory qdisc-fifo.data shadow.yaml &gt; qdisc-fifo.log
shadow --interface-qdisc roundrobin --data-directory qdisc-rr.data   shadow.yaml &gt; qdisc-rr.log
</code></pre>
<p>To parse these log files, we use the following scripts:</p>
<pre><code class="language-bash">src/tools/parse-shadow.py --prefix=qdisc-fifo.results qdisc-fifo.log
src/tools/parse-shadow.py --prefix=qdisc-rr.results   qdisc-rr.log
</code></pre>
<p>Each of the directories <code>qdisc-fifo.results/</code> and <code>qdisc-rr.results/</code> now contain data statistics files extracted from the log files. We can now combine and visualize these results with the <code>plot-shadow.py</code> script:</p>
<pre><code class="language-bash">src/tools/plot-shadow.py --prefix &quot;qdisc&quot; --data qdisc-fifo.results/ &quot;fifo&quot; --data qdisc-rr.results/ &quot;round-robin&quot;
</code></pre>
<p>Open the PDF file that was created to compare results from the experiments.</p>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h1 id="log-format"><a class="header" href="#log-format">Log Format</a></h1>
<h2 id="log-line-prefix"><a class="header" href="#log-line-prefix">Log Line Prefix</a></h2>
<p>Shadow produces simulator log messages in the following format:</p>
<pre><code class="language-text">real-time [thread-id] virtual-time [logdomain-loglevel] [hostname~ip] [function-name] MESSAGE
</code></pre>
<p><strong>FIXME</strong>: The <code>real-time</code> and <code>virtual-time</code> use different time units. Is this correct, or should we change this in Shadow?</p>
<ul>
<li><code>real-time</code>:<br />
the wall clock time since the start of the experiment, represented as <code>hours:minutes:seconds:microseconds</code></li>
<li><code>thread-id</code>:<br />
the ID of the worker thread that generated the message</li>
<li><code>virtual-time</code>:<br />
the simulated time since the start of the experiment, represented as <code>hours:minutes:seconds:nanoseconds</code></li>
<li><code>logdomain</code>:<br />
either <code>shadow</code> or the name of one of the applications as specified in the <em>id</em> tag of the <em>plugin</em> element in the XML file (e.g., <code>tgen</code>, <code>tor</code>, <code>bitcoin</code>)</li>
<li><code>loglevel</code>:<br />
one of <code>error</code> &lt; <code>critical</code> &lt; <code>warning</code> &lt; <code>message</code> &lt; <code>info</code> &lt; <code>debug</code>, in that order</li>
<li><code>hostname</code>:<br />
the name of the node as specified in the <em>id</em> tag of the <em>node</em> element in the XML file</li>
<li><code>ip</code>:<br />
the IP address of the node as specified in the <em>ip</em> tag of the <em>node</em> element in the XML file, or a random IP address if one is not specified</li>
<li><code>function-name</code>:<br />
the name of the function logging the message</li>
<li><code>MESSAGE</code>:<br />
the actual message to be logged</li>
</ul>
<p>By default, Shadow only prints core messages at or below the <code>message</code> log level. This behavior can be changed using the Shadow option <code>-l</code> or <code>--log-level</code> to increase or decrease the verbosity of the output. As mentioned in the example from the previous section, the output from each application process is stored in separate log files beneath the <code>shadow.data</code> directory, and the format of those log files is application-specific (i.e., Shadow writes application output <em>directly</em> to file).</p>
<h2 id="heartbeat-messages"><a class="header" href="#heartbeat-messages">Heartbeat Messages</a></h2>
<p>Shadow logs simulator heartbeat messages that contain useful system information for each virtual node in the experiment, in messages containing the string <code>shadow-heartbeat</code>. By default, these heartbeats are logged once per second, but the frequency can be changed using the <code>--heartbeat-frequency</code> option to Shadow (see <code>shadow --help</code>).</p>
<p>There are currently three heartbeat statistic subsystems: <code>node</code>, <code>socket</code>, and <code>ram</code>. For each subsystem that is enabled, Shadow will print a 'header' message followed by regular message every frequency interval. The 'header' messages generally describe the statistics that are printed in the regular messages for that subsystem.</p>
<p>The following are examples of the statistics that are available for each subsystem:</p>
<p>Node:</p>
<pre><code>[node-header] interval-seconds,recv-bytes,send-bytes,cpu-percent,delayed-count,avgdelay-milliseconds;inbound-localhost-counters;outbound-localhost-counters;inbound-remote-counters;outbound-remote-counters where counters are: packets-total,bytes-total,packets-control,bytes-control-header,packets-control-retrans,bytes-control-header-retrans,packets-data,bytes-data-header,bytes-data-payload,packets-data-retrans,bytes-data-header-retrans,bytes-data-payload-retrans
</code></pre>
<p>Socket:</p>
<pre><code>[socket-header] descriptor-number,protocol-string,hostname:port-peer;inbuflen-bytes,inbufsize-bytes,outbuflen-bytes,outbufsize-bytes;recv-bytes,send-bytes;inbound-localhost-counters;outbound-localhost-counters;inbound-remote-counters;outbound-remote-counters|...where counters are: packets-total,bytes-total,packets-control,bytes-control-header,packets-control-retrans,bytes-control-header-retrans,packets-data,bytes-data-header,bytes-data-payload,packets-data-retrans,bytes-data-header-retrans,bytes-data-payload-retrans
</code></pre>
<p>Ram:</p>
<pre><code>[ram-header] interval-seconds,alloc-bytes,dealloc-bytes,total-bytes,pointers-count,failfree-count
</code></pre>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="mission-run-tor-in-a-box"><a class="header" href="#mission-run-tor-in-a-box">Mission: Run Tor in a Box</a></h2>
<table><thead><tr><th>❗ Notice</th></tr></thead><tbody>
<tr><td>This overview describes Shadow's original<br>architecture (version 1.x) and not the current<br>architecture.</td></tr>
</tbody></table>
<br>
<!--[[https://raw.githubusercontent.com/wiki/shadow/shadow/assets/torinabox.png|align=right|width=175px]]-->
<!--[Run Tor in a box with Shadow!][image-torinabox]-->
<!--[image-torinabox]: https://raw.githubusercontent.com/wiki/shadow/shadow/assets/torinabox.png-->
<p><a href="https://raw.githubusercontent.com/wiki/shadow/shadow/assets/torinabox.png"><img align="right" width="225" alt="Run Tor in a box with Shadow!" src="https://raw.githubusercontent.com/wiki/shadow/shadow/assets/torinabox.png"></a></p>
<p>Shadow was developed because there was a recognized need for an accurate, efficient, and scalable tool for Tor experimentation: using the PlanetLab platform is undesirable due to management overhead and lack of control; existing emulators are far too inefficient when scaling to thousands of nodes; roll-your-own simulators are often too inaccurate or generic to be useful for multiple projects; and experiments on the live Tor network are often infeasible due to privacy risks.</p>
<p>Our goal was to provide a tool that can be used by anyone with a Linux machine or access to EC2 to hasten the development of research prototypes and reduce the time to deployment. Although originally written with Tor experimentation in mind, Shadow can also run Bitcoin and is useful for researching or prototyping other distributed or peer-to-peer systems including multi-party computation protocols.</p>
<h2 id="feature-overview"><a class="header" href="#feature-overview">Feature Overview</a></h2>
<p>Shadow does the following:</p>
<ul>
<li>creates an isolated simulation environment where virtual hosts may communicate with each other but not with the Internet</li>
<li>natively executes <strong>real applications</strong> like Tor and Bitcoin </li>
<li>provides efficient, accurate, and <strong>controlled</strong> experiments</li>
<li>models network topology, latency, and bandwidth</li>
<li>runs without root on a single Linux machine</li>
<li>simulates multiple virtual hosts in virtual time</li>
<li>simulates the network (TCP stack) and CPU processing delays</li>
<li>can run private Tor networks with user/traffic models based on <a href="https://metrics.torproject.org/">Tor metrics</a> </li>
<li>much, much more!</li>
</ul>
<h2 id="real-applications-as-shadow-plug-ins"><a class="header" href="#real-applications-as-shadow-plug-ins">Real Applications as Shadow Plug-ins</a></h2>
<p>Shadow is a discrete-event simulator that runs <strong>real applications</strong> like <a href="https://www.torproject.org/">Tor</a> . Shadow links to real application software and <strong>natively executes the application code</strong> during simulation, providing faithful experiments and accurate results. Shadow models and runs distributed networks using these applications on a single Linux machine, easing experiment management while keeping the focus on the results.</p>
<h4 id="what-are-plug-ins"><a class="header" href="#what-are-plug-ins">What are Plug-ins?</a></h4>
<p>Plug-ins are shared library shims that are linked to real applications. Shadow dynamically loads these libraries to natively execute the application code. Shadow intercepts a selective set of system calls to enable seamless integration of an application to the simulated environment. In this way, the application may be unaware that it is running in the simulator and will function as if it was running in a standard UNIX environment.</p>
<p>Visit <a href="https://github.com/shadow/shadow/wiki/2-Simulation-Execution-and-Analysis#shadow-plug-ins">this page on the wiki</a> for more information about how to write your own custom Shadow plug-in.</p>
<h4 id="what-is-shadow-plugin-tor"><a class="header" href="#what-is-shadow-plugin-tor">What is shadow-plugin-tor?</a></h4>
<p>shadow-plugin-tor is a Shadow plug-in for simulating the <a href="https://www.torproject.org/">Tor</a> anonymity network. shadow-plugin-tor integrates Tor into Shadow by wrapping the <a href="https://gitweb.torproject.org/tor.git">Tor source code</a> with the necessary hooks that allow it to communicate with the Shadow simulator, thereby leveraging Shadow's unique functionality to allow rapid prototyping and experimentation of Tor. shadow-plugin-tor also contains scripts that assist in analyzing results, generating Tor topologies, and running experiments using the generated topologies.</p>
<p>Visit <a href="https://github.com/shadow/shadow-plugin-tor/wiki">the shadow-plugin-tor wiki page</a> for more information on the Tor plug-in and its memory requirements.</p>
<h2 id="simulation-blueprint"><a class="header" href="#simulation-blueprint">Simulation Blueprint</a></h2>
<p>The first step to using Shadow is to create a blueprint of an experiment. The format of the blueprint is standard XML. The XML file tells Shadow when it should create each virtual host, what software each virtual host should run. It also specifies the structure of the network topology, and network properties such as link latency, jitter, and packet loss rates. Shadow contains example XML files to help get started!</p>
<p><a href="https://raw.githubusercontent.com/wiki/shadow/shadow/assets/design1.png"><img title="design1" src="https://raw.githubusercontent.com/wiki/shadow/shadow/assets/design1.png" alt="" width="520" /></a></p>
<p><em>Shadow takes a simulation blueprint as input. This XML file specifies the structure of the topology and the general flow of the experiment. Shadow's event engine initializes hosts using the blueprint, and runs events on their behalf until the simulation is complete.</em></p>
<h2 id="discrete-time-events"><a class="header" href="#discrete-time-events">Discrete Time Events</a></h2>
<p>Shadow creates several bootstrapping events after extracting the information from the supplied XML blueprint file. Each of these events are executed at a discrete time instant during the experiment. Each of these bootstrapping events will cause the virtual hosts to start executing the specified software, which in turn will spawn additional events for Shadow to process. Shadow tracks the time each virtual host spends processing inside the application, and delays events according to the host's configured virtual CPU speed. Events are continuously executed until the simulation end time.</p>
<p>As applications send data to each other, Shadow packages that data into an internal type and transfers the pointer between various queues. This process involves the use of the main Shadow event queue to transfer the packet events between virtual hosts, and rate-limiting to ensure each host has the desired bandwidth capacity. The following image, courtesy of Steven Murdoch, may help visualize this process:</p>
<p><a href="https://raw.githubusercontent.com/wiki/shadow/shadow/assets/shadow_packet_flow.pdf"><img title="shadow_packet_flow" src="shadow/assets/shadow_packet_flow.svg" alt="" width="520" /></a></p>
<p><em>End-to-end application data flows through Shadow socket and interface buffers, while the discrete event queue facilitates the transfer of data between virtual hosts.</em></p>
<h2 id="virtual-host-management"><a class="header" href="#virtual-host-management">Virtual Host Management</a></h2>
<p>Each virtual host in Shadow runs real software, which are linked as Shadow plug-ins. For each instance of the plug-in that a host is configured to run, Shadow loads the plug-in into a private namespace container using a custom loader and <code>dlmopen()</code>. The loader takes care to minimize duplicated memory usage on multiple loads of the same plug-in.</p>
<p>With the virtual host's plug-in loaded, execution is then passed to the application by calling the <code>main()</code> function using a version of <a href="https://www.gnu.org/software/pth/">GNU portable threads (pth)</a>. Pth is an application-space non-preemptive priority-based threading library that can jump call stacks to support plug-ins that run multiple threads and block during execution. Shadow runs the plug-in instance until it would block, and then moves on to execute other plug-ins and hosts.</p>
<h2 id="function-interposition"><a class="header" href="#function-interposition">Function Interposition</a></h2>
<p>Shadow runs real applications that run on regular UNIX-type systems. These applications expect a wide range of kernel libraries to be available for use. For example, sending and receiving data over the network, system time, and device polling are all generally handled by the kernel at some level. These system functions (and others) are intercepted and redirected through Shadow-specific versions. In this way, Shadow provides the ability for hosts to seamlessly communicate with each other over the virtual network without requiring any changes to the application code.</p>
<h2 id="more-information"><a class="header" href="#more-information">More information</a></h2>
<p>See <a href="http://youtu.be/Tb7m8OdpD8A">the original Shadow webcast</a> for more information about Shadow's original design, and for an explanation of some experiments that utilize this unique architecture. An explanation of recent architecture updates to support blocking system calls (read/write/send/recv/sleep) and applications that spawn threads <a href="http://www.robgjansen.com/talks/shadowbitcoin-cset-20150810.pdf">can be found here</a>. Checkout <a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12341442653770148265">Google Scholar</a> for research publications that cite Shadow.</p>
<!--<iframe width="420" height="315" src="http://www.youtube-nocookie.com/embed/Tb7m8OdpD8A" frameborder="0" allowfullscreen></iframe>-->
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="shadow/notes_and_faq.html#shadow-is-running-at-100-cpu-is-that-normal">Shadow is running at 100% CPU. Is that normal?</a></li>
<li><a href="shadow/notes_and_faq.html#is-it-possible-to-achieve-deterministic-experiments-so-that-every-time-i-run-shadow-with-the-same-configuration-file-i-get-the-same-results">Is it possible to achieve deterministic experiments, so that every time I run Shadow with the same configuration file, I get the same results?</a></li>
<li><a href="shadow/notes_and_faq.html#why-dont-the-consensus-values-from-a-v3bw-file-for-the-torflowauthority-show-up-in-the-directory-authoritys-cached-consenus-file">Why don't the consensus values from a v3bw file for the torflowauthority show up in the directory authority's <code>cached-consenus</code> file?</a></li>
<li><a href="shadow/notes_and_faq.html#is-shadow-the-right-tool-for-my-research-question">Is Shadow the right tool for my research question?</a></li>
</ul>
<h4 id="shadow-is-running-at-100-cpu-is-that-normal"><a class="header" href="#shadow-is-running-at-100-cpu-is-that-normal">Shadow is running at 100% CPU. Is that normal?</a></h4>
<p>Yes. In single-thread mode, Shadow runs at 100% CPU because its continuously processing simulation events as fast as possible. All other things constant, an experiment will finish quicker with a faster CPU. Due to node dependencies, thread CPU utilization will be less than 100% in multi-thread mode.</p>
<h4 id="is-it-possible-to-achieve-deterministic-experiments-so-that-every-time-i-run-shadow-with-the-same-configuration-file-i-get-the-same-results"><a class="header" href="#is-it-possible-to-achieve-deterministic-experiments-so-that-every-time-i-run-shadow-with-the-same-configuration-file-i-get-the-same-results">Is it possible to achieve deterministic experiments, so that every time I run Shadow with the same configuration file, I get the same results?</a></h4>
<p>Todo!</p>
<h4 id="why-dont-the-consensus-values-from-a-v3bw-file-for-the-torflowauthority-show-up-in-the-directory-authoritys-cached-consenus-file"><a class="header" href="#why-dont-the-consensus-values-from-a-v3bw-file-for-the-torflowauthority-show-up-in-the-directory-authoritys-cached-consenus-file">Why don't the consensus values from a v3bw file for the torflowauthority show up in the directory authority's <code>cached-consenus</code> file?</a></h4>
<p>Tor currently requires 3 directory authorities to be configured in order to accept values from a v3bw file; otherwise the directory authorities use relays' advertised bandwidth when creating the consensus and the v3bw file entries are ignored.</p>
<h4 id="is-shadow-the-right-tool-for-my-research-question"><a class="header" href="#is-shadow-the-right-tool-for-my-research-question">Is Shadow the right tool for my research question?</a></h4>
<p>Shadow is a network simulator/emulator hybrid. It runs real applications, but it simulates network and system functions thereby emulating the kernel to the application. The suitability of Shadow to your problem depends upon what exactly you are trying to measure. If you are interested in analyzing changes in application behavior, e.g. application layer queuing, failure modes, or design changes, and how those changes affect the operation of the system and  network performance, then Shadow seems like a very good choice (especially if you want to minimize work on your end). If your research relies on, e.g., the accuracy of specific kernel features or kernel parameter settings, or dynamic changes in Internet routing, then Shadow may not be the right choice as it does not precisely model these behaviors. Shadow is also not the best at measuring cryptographic overhead, so if that is desired then it should probably be done more directly as a separate research component.</p>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><p>Shadow uses the standard YAML format to accept configuration options from users. Examples of a Shadow configuration file, <code>shadow.config.yaml</code>, are distributed with the release. The following describes Shadow's YAML format that can be used to customize a simulation.</p>
<p>Example:</p>
<pre><code class="language-yaml">general:
  stop_time: 2 min
network:
  graph:
    type: 1_gbit_switch
hosts:
  server:
    processes:
    - path: /usr/sbin/nginx
      args: -c ../../../nginx.conf -p .
      start_time: 1
  client:
    quantity: 20
    processes:
    - path: /usr/bin/curl
      args: server --silent
      start_time: 5
</code></pre>
<h2 id="contents"><a class="header" href="#contents">Contents:</a></h2>
<ul>
<li><a href="shadow/shadow_config.html#general"><code>general</code></a></li>
<li><a href="shadow/shadow_config.html#generalbootstrap_end_time"><code>general.bootstrap_end_time</code></a></li>
<li><a href="shadow/shadow_config.html#generaldata_directory"><code>general.data_directory</code></a></li>
<li><a href="shadow/shadow_config.html#generalheartbeat_interval"><code>general.heartbeat_interval</code></a></li>
<li><a href="shadow/shadow_config.html#generallog_level"><code>general.log_level</code></a></li>
<li><a href="shadow/shadow_config.html#generalparallelism"><code>general.parallelism</code></a></li>
<li><a href="shadow/shadow_config.html#generalseed"><code>general.seed</code></a></li>
<li><a href="shadow/shadow_config.html#generalstop_time"><code>general.stop_time</code></a></li>
<li><a href="shadow/shadow_config.html#generaltemplate_directory"><code>general.template_directory</code></a></li>
<li><a href="shadow/shadow_config.html#network"><code>network</code></a></li>
<li><a href="shadow/shadow_config.html#networkgraph"><code>network.graph</code></a></li>
<li><a href="shadow/shadow_config.html#networkgraphtype"><code>network.graph.type</code></a></li>
<li><a href="shadow/shadow_config.html#networkgraphpathinline"><code>network.graph.&lt;path|inline&gt;</code></a></li>
<li><a href="shadow/shadow_config.html#networkuse_shortest_path"><code>network.use_shortest_path</code></a></li>
<li><a href="shadow/shadow_config.html#experimental"><code>experimental</code></a></li>
<li><a href="shadow/shadow_config.html#experimentalinterface_buffer"><code>experimental.interface_buffer</code></a></li>
<li><a href="shadow/shadow_config.html#experimentalinterface_qdisc"><code>experimental.interface_qdisc</code></a></li>
<li><a href="shadow/shadow_config.html#experimentalinterpose_method"><code>experimental.interpose_method</code></a></li>
<li><a href="shadow/shadow_config.html#experimentalpreload_spin_max"><code>experimental.preload_spin_max</code></a></li>
<li><a href="shadow/shadow_config.html#experimentalrunahead"><code>experimental.runahead</code></a></li>
<li><a href="shadow/shadow_config.html#experimentalscheduler_policy"><code>experimental.scheduler_policy</code></a></li>
<li><a href="shadow/shadow_config.html#experimentalsocket_recv_autotune"><code>experimental.socket_recv_autotune</code></a></li>
<li><a href="shadow/shadow_config.html#experimentalsocket_recv_buffer"><code>experimental.socket_recv_buffer</code></a></li>
<li><a href="shadow/shadow_config.html#experimentalsocket_send_autotune"><code>experimental.socket_send_autotune</code></a></li>
<li><a href="shadow/shadow_config.html#experimentalsocket_send_buffer"><code>experimental.socket_send_buffer</code></a></li>
<li><a href="shadow/shadow_config.html#experimentaluse_cpu_pinning"><code>experimental.use_cpu_pinning</code></a></li>
<li><a href="shadow/shadow_config.html#experimentaluse_explicit_block_message"><code>experimental.use_explicit_block_message</code></a></li>
<li><a href="shadow/shadow_config.html#experimentaluse_legacy_working_dir"><code>experimental.use_legacy_working_dir</code></a></li>
<li><a href="shadow/shadow_config.html#experimentaluse_memory_manager"><code>experimental.use_memory_manager</code></a></li>
<li><a href="shadow/shadow_config.html#experimentaluse_o_n_waitpid_workarounds"><code>experimental.use_o_n_waitpid_workarounds</code></a></li>
<li><a href="shadow/shadow_config.html#experimentaluse_object_counters"><code>experimental.use_object_counters</code></a></li>
<li><a href="shadow/shadow_config.html#experimentaluse_sched_fifo"><code>experimental.use_sched_fifo</code></a></li>
<li><a href="shadow/shadow_config.html#experimentaluse_shim_syscall_handler"><code>experimental.use_shim_syscall_handler</code></a></li>
<li><a href="shadow/shadow_config.html#experimentaluse_syscall_counters"><code>experimental.use_syscall_counters</code></a></li>
<li><a href="shadow/shadow_config.html#experimentalworker_threads"><code>experimental.worker_threads</code></a></li>
<li><a href="shadow/shadow_config.html#host_defaults"><code>host_defaults</code></a></li>
<li><a href="shadow/shadow_config.html#host_defaultscity_code_hint"><code>host_defaults.city_code_hint</code></a></li>
<li><a href="shadow/shadow_config.html#host_defaultscountry_code_hint"><code>host_defaults.country_code_hint</code></a></li>
<li><a href="shadow/shadow_config.html#host_defaultsheartbeat_interval"><code>host_defaults.heartbeat_interval</code></a></li>
<li><a href="shadow/shadow_config.html#host_defaultsheartbeat_log_info"><code>host_defaults.heartbeat_log_info</code></a></li>
<li><a href="shadow/shadow_config.html#host_defaultsheartbeat_log_level"><code>host_defaults.heartbeat_log_level</code></a></li>
<li><a href="shadow/shadow_config.html#host_defaultsip_address_hint"><code>host_defaults.ip_address_hint</code></a></li>
<li><a href="shadow/shadow_config.html#host_defaultslog_level"><code>host_defaults.log_level</code></a></li>
<li><a href="shadow/shadow_config.html#host_defaultspcap_directory"><code>host_defaults.pcap_directory</code></a></li>
<li><a href="shadow/shadow_config.html#hosts"><code>hosts</code></a></li>
<li><a href="shadow/shadow_config.html#hostshostnamebandwidth_down"><code>hosts.&lt;hostname&gt;.bandwidth_down</code></a></li>
<li><a href="shadow/shadow_config.html#hostshostnamebandwidth_up"><code>hosts.&lt;hostname&gt;.bandwidth_up</code></a></li>
<li><a href="shadow/shadow_config.html#hostshostnameoptions"><code>hosts.&lt;hostname&gt;.options</code></a></li>
<li><a href="shadow/shadow_config.html#hostshostnamequantity"><code>hosts.&lt;hostname&gt;.quantity</code></a></li>
<li><a href="shadow/shadow_config.html#hostshostnameprocesses"><code>hosts.&lt;hostname&gt;.processes</code></a></li>
<li><a href="shadow/shadow_config.html#hostshostnameprocessesargs"><code>hosts.&lt;hostname&gt;.processes[*].args</code></a></li>
<li><a href="shadow/shadow_config.html#hostshostnameprocessesenvironment"><code>hosts.&lt;hostname&gt;.processes[*].environment</code></a></li>
<li><a href="shadow/shadow_config.html#hostshostnameprocessespath"><code>hosts.&lt;hostname&gt;.processes[*].path</code></a></li>
<li><a href="shadow/shadow_config.html#hostshostnameprocessesquantity"><code>hosts.&lt;hostname&gt;.processes[*].quantity</code></a></li>
<li><a href="shadow/shadow_config.html#hostshostnameprocessesstart_time"><code>hosts.&lt;hostname&gt;.processes[*].start_time</code></a></li>
<li><a href="shadow/shadow_config.html#hostshostnameprocessesstop_time"><code>hosts.&lt;hostname&gt;.processes[*].stop_time</code></a></li>
</ul>
<h4 id="general"><a class="header" href="#general"><code>general</code></a></h4>
<p><em>Required</em></p>
<p>General experiment settings.</p>
<h4 id="generalbootstrap_end_time"><a class="header" href="#generalbootstrap_end_time"><code>general.bootstrap_end_time</code></a></h4>
<p>Default: &quot;0 sec&quot;<br />
Type: String OR Integer</p>
<h4 id="generaldata_directory"><a class="header" href="#generaldata_directory"><code>general.data_directory</code></a></h4>
<p>Default: &quot;shadow.data&quot;<br />
Type: String</p>
<p>Path to store simulation output.</p>
<h4 id="generalheartbeat_interval"><a class="header" href="#generalheartbeat_interval"><code>general.heartbeat_interval</code></a></h4>
<p>Default: &quot;1 sec&quot;<br />
Type: String OR Integer</p>
<p>Interval at which to print heartbeat messages.</p>
<h4 id="generallog_level"><a class="header" href="#generallog_level"><code>general.log_level</code></a></h4>
<p>Default: &quot;info&quot;<br />
Type: &quot;error&quot; OR &quot;warning&quot; OR &quot;info&quot; OR &quot;debug&quot; OR &quot;trace&quot;</p>
<p>Log level of output written on stdout. If Shadow was built in release mode, then messages at level 'trace' will always be dropped.</p>
<h4 id="generalparallelism"><a class="header" href="#generalparallelism"><code>general.parallelism</code></a></h4>
<p>Default: 1<br />
Type: Integer</p>
<p>How many parallel threads to use to run the simulation. Optimal performance is
usually obtained with <code>nproc</code>, or sometimes <code>nproc/2</code> with hyperthreading.</p>
<p>Virtual hosts depend on network packets that can potentially arrive from other virtual hosts, so each worker can only advance according to the propagation delay to avoid dependency violations. Therefore, not all threads will have 100% CPU utilization.</p>
<h4 id="generalseed"><a class="header" href="#generalseed"><code>general.seed</code></a></h4>
<p>Default: 1<br />
Type: Integer</p>
<p>Initialize randomness using seed N.</p>
<h4 id="generalstop_time"><a class="header" href="#generalstop_time"><code>general.stop_time</code></a></h4>
<p><em>Required</em><br />
Type: String OR Integer</p>
<p>The simulated time at which simulated processes are sent a SIGKILL signal.</p>
<h4 id="generaltemplate_directory"><a class="header" href="#generaltemplate_directory"><code>general.template_directory</code></a></h4>
<p>Default: null<br />
Type: String OR null</p>
<p>Path to recursively copy during startup and use as the data-directory.</p>
<h4 id="network"><a class="header" href="#network"><code>network</code></a></h4>
<p><em>Required</em></p>
<p>Network topology settings.</p>
<h4 id="networkgraph"><a class="header" href="#networkgraph"><code>network.graph</code></a></h4>
<p><em>Required</em></p>
<p>The network topology graph.</p>
<p>A network topology represented by a connected graph with certain attributes specified on the nodes and edges. For more information on how to structure this data, see the <a href="shadow/network_config.html">Topology Format</a>.</p>
<p>Example:</p>
<pre><code class="language-yaml">network:
  graph:
    type: gml
    inline: |
      graph [
        ...
      ]
</code></pre>
<h4 id="networkgraphtype"><a class="header" href="#networkgraphtype"><code>network.graph.type</code></a></h4>
<p><em>Required</em><br />
Type: &quot;gml&quot; OR &quot;1_gbit_switch&quot;</p>
<p>The network graph can be specified in the GML format, or a built-in &quot;1_gbit_switch&quot; graph with a single node can be used instead.</p>
<h4 id="networkgraphpathinline"><a class="header" href="#networkgraphpathinline"><code>network.graph.&lt;path|inline&gt;</code></a></h4>
<p><em>Required if <code>network.graph.type</code> is <code>gml</code></em><br />
Type: String</p>
<p>If the network graph type is not a built-in network graph, the graph data can be specified as a path to an external file, or as an inline string.</p>
<p>If a path is given and begins with <code>~/</code>, it will be considered relative to the current user's home directory.</p>
<h4 id="networkuse_shortest_path"><a class="header" href="#networkuse_shortest_path"><code>network.use_shortest_path</code></a></h4>
<p><em>Required</em>
Type: Bool</p>
<p>When routing packets, follow the shortest path rather than following a direct edge between nodes. If false, the network graph is required to be complete.</p>
<h4 id="experimental"><a class="header" href="#experimental"><code>experimental</code></a></h4>
<p>Experimental experiment settings. Unstable and may change or be removed at any time, regardless of Shadow version.</p>
<h4 id="experimentalinterface_buffer"><a class="header" href="#experimentalinterface_buffer"><code>experimental.interface_buffer</code></a></h4>
<p>Default: &quot;1024000 B&quot;<br />
Type: String OR Integer</p>
<p>Size of the interface receive buffer that accepts incoming packets.</p>
<h4 id="experimentalinterface_qdisc"><a class="header" href="#experimentalinterface_qdisc"><code>experimental.interface_qdisc</code></a></h4>
<p>Default: &quot;fifo&quot;<br />
Type: &quot;fifo&quot; OR &quot;roundrobin&quot;</p>
<p>The queueing discipline to use at the network interface.</p>
<h4 id="experimentalinterpose_method"><a class="header" href="#experimentalinterpose_method"><code>experimental.interpose_method</code></a></h4>
<p>Default: &quot;ptrace&quot;<br />
Type: &quot;ptrace&quot; OR &quot;preload&quot; OR &quot;hybrid&quot;</p>
<p>Which interposition method to use.</p>
<h4 id="experimentalpreload_spin_max"><a class="header" href="#experimentalpreload_spin_max"><code>experimental.preload_spin_max</code></a></h4>
<p>Default: 0<br />
Type: Integer</p>
<p>Max number of iterations to busy-wait on IPC semaphore before blocking.</p>
<h4 id="experimentalrunahead"><a class="header" href="#experimentalrunahead"><code>experimental.runahead</code></a></h4>
<p>Default: null<br />
Type: String OR null</p>
<p>If set, overrides the automatically calculated minimum time workers may run ahead when sending events between nodes.</p>
<h4 id="experimentalscheduler_policy"><a class="header" href="#experimentalscheduler_policy"><code>experimental.scheduler_policy</code></a></h4>
<p>Default: &quot;host&quot;<br />
Type: &quot;host&quot; OR &quot;steal&quot; OR &quot;thread&quot; OR &quot;threadxthread&quot; OR &quot;threadxhost&quot;</p>
<p>The event scheduler's policy for thread synchronization.</p>
<h4 id="experimentalsocket_recv_autotune"><a class="header" href="#experimentalsocket_recv_autotune"><code>experimental.socket_recv_autotune</code></a></h4>
<p>Default: true<br />
Type: Bool</p>
<p>Enable receive window autotuning.</p>
<h4 id="experimentalsocket_recv_buffer"><a class="header" href="#experimentalsocket_recv_buffer"><code>experimental.socket_recv_buffer</code></a></h4>
<p>Default: &quot;174760 B&quot;<br />
Type: String OR Integer</p>
<p>Initial size of the socket's receive buffer.</p>
<h4 id="experimentalsocket_send_autotune"><a class="header" href="#experimentalsocket_send_autotune"><code>experimental.socket_send_autotune</code></a></h4>
<p>Default: true<br />
Type: Bool</p>
<p>Enable send window autotuning.</p>
<h4 id="experimentalsocket_send_buffer"><a class="header" href="#experimentalsocket_send_buffer"><code>experimental.socket_send_buffer</code></a></h4>
<p>Default: &quot;131072 B&quot;<br />
Type: String OR Integer</p>
<p>Initial size of the socket's send buffer.</p>
<h4 id="experimentaluse_cpu_pinning"><a class="header" href="#experimentaluse_cpu_pinning"><code>experimental.use_cpu_pinning</code></a></h4>
<p>Default: true<br />
Type: Bool</p>
<p>Pin each thread and any processes it executes to the same logical CPU Core to improve cache affinity.</p>
<h4 id="experimentaluse_explicit_block_message"><a class="header" href="#experimentaluse_explicit_block_message"><code>experimental.use_explicit_block_message</code></a></h4>
<p>Default: false<br />
Type: Bool</p>
<p>Send message to plugin telling it to stop spinning when a syscall blocks.</p>
<h4 id="experimentaluse_legacy_working_dir"><a class="header" href="#experimentaluse_legacy_working_dir"><code>experimental.use_legacy_working_dir</code></a></h4>
<p>Default: false<br />
Type: Bool</p>
<p>Don't adjust the working directories of the plugins.</p>
<h4 id="experimentaluse_memory_manager"><a class="header" href="#experimentaluse_memory_manager"><code>experimental.use_memory_manager</code></a></h4>
<p>Default: true<br />
Type: Bool</p>
<p>Use the MemoryManager. It can be useful to disable for debugging, but will hurt performance in most cases.</p>
<h4 id="experimentaluse_o_n_waitpid_workarounds"><a class="header" href="#experimentaluse_o_n_waitpid_workarounds"><code>experimental.use_o_n_waitpid_workarounds</code></a></h4>
<p>Default: false
Type: Bool</p>
<p>Use performance workarounds for waitpid being O(n). Beneficial to disable if waitpid is patched to be O(1), if using one logical processor per host, or in some cases where it'd otherwise result in excessive detaching and reattaching.</p>
<h4 id="experimentaluse_object_counters"><a class="header" href="#experimentaluse_object_counters"><code>experimental.use_object_counters</code></a></h4>
<p>Default: true<br />
Type: Bool</p>
<p>Count object allocations and deallocations. If disabled, we will not be able to detect object memory leaks.</p>
<h4 id="experimentaluse_sched_fifo"><a class="header" href="#experimentaluse_sched_fifo"><code>experimental.use_sched_fifo</code></a></h4>
<p>Default: false<br />
Type: Bool</p>
<p>Use the SCHED_FIFO scheduler. Requires CAP_SYS_NICE. See sched(7), capabilities(7).</p>
<h4 id="experimentaluse_shim_syscall_handler"><a class="header" href="#experimentaluse_shim_syscall_handler"><code>experimental.use_shim_syscall_handler</code></a></h4>
<p>Default: true<br />
Type: Bool</p>
<p>Use shim-side syscall handler to force hot-path syscalls to be handled via an inter-process syscall with Shadow.</p>
<h4 id="experimentaluse_syscall_counters"><a class="header" href="#experimentaluse_syscall_counters"><code>experimental.use_syscall_counters</code></a></h4>
<p>Default: false<br />
Type: Bool</p>
<p>Count the number of occurrences for individual syscalls.</p>
<h4 id="experimentalworker_threads"><a class="header" href="#experimentalworker_threads"><code>experimental.worker_threads</code></a></h4>
<p>Default: # of hosts in the simulation<br />
Type: Integer</p>
<p>Create N worker threads. Note though, that <code>general.parallelism</code> of them will be
allowed to run simultaneously. If unset, will create a thread for each simulated
Host. This is to work around limitations in ptrace, and may change in the
future.</p>
<h4 id="host_defaults"><a class="header" href="#host_defaults"><code>host_defaults</code></a></h4>
<p>Default options for all hosts. These options can also be overridden for each host individually.</p>
<h4 id="host_defaultscity_code_hint"><a class="header" href="#host_defaultscity_code_hint"><code>host_defaults.city_code_hint</code></a></h4>
<p>Default: null<br />
Type: String OR null</p>
<p>City code hint for Shadow's name and routing system.</p>
<p>This hint will be used to assign the host to a node based on the city codes of nodes in the network topology.</p>
<h4 id="host_defaultscountry_code_hint"><a class="header" href="#host_defaultscountry_code_hint"><code>host_defaults.country_code_hint</code></a></h4>
<p>Default: null<br />
Type: String OR null</p>
<p>Country code hint for Shadow's name and routing system (ex: &quot;US&quot;).</p>
<p>This hint will be used to assign the host to a node based on the country codes of nodes in the network topology.</p>
<h4 id="host_defaultsheartbeat_interval"><a class="header" href="#host_defaultsheartbeat_interval"><code>host_defaults.heartbeat_interval</code></a></h4>
<p>Default: &quot;1 sec&quot;<br />
Type: String OR Integer</p>
<p>Amount of time between heartbeat messages for this host.</p>
<h4 id="host_defaultsheartbeat_log_info"><a class="header" href="#host_defaultsheartbeat_log_info"><code>host_defaults.heartbeat_log_info</code></a></h4>
<p>Default: [&quot;node&quot;]<br />
Type: Array of (&quot;node&quot; OR &quot;socket&quot; OR &quot;ram&quot;)</p>
<p>List of information to show in the host's heartbeat message.</p>
<h4 id="host_defaultsheartbeat_log_level"><a class="header" href="#host_defaultsheartbeat_log_level"><code>host_defaults.heartbeat_log_level</code></a></h4>
<p>Default: &quot;info&quot;<br />
Type: &quot;error&quot; OR &quot;warning&quot; OR &quot;info&quot; OR &quot;debug&quot; OR &quot;trace&quot;</p>
<p>Log level at which to print host statistics.</p>
<h4 id="host_defaultsip_address_hint"><a class="header" href="#host_defaultsip_address_hint"><code>host_defaults.ip_address_hint</code></a></h4>
<p>Default: null<br />
Type: String OR null</p>
<p>IPv4 address hint for Shadow's name and routing system (ex: &quot;100.0.0.1&quot;).</p>
<p>This hint will be used to assign the host to a node based on the IP values of nodes in the network topology.</p>
<h4 id="host_defaultslog_level"><a class="header" href="#host_defaultslog_level"><code>host_defaults.log_level</code></a></h4>
<p>Default: null<br />
Type: &quot;error&quot; OR &quot;warning&quot; OR &quot;info&quot; OR &quot;debug&quot; OR &quot;trace&quot; OR null</p>
<p>Log level at which to print node messages.</p>
<h4 id="host_defaultspcap_directory"><a class="header" href="#host_defaultspcap_directory"><code>host_defaults.pcap_directory</code></a></h4>
<p>Default: null<br />
Type: String OR null</p>
<p>Where to save the pcap files (relative to the host directory).</p>
<p>Logs all network input and output for this host in PCAP format (for viewing in e.g. wireshark).</p>
<h4 id="hosts"><a class="header" href="#hosts"><code>hosts</code></a></h4>
<p><em>Required</em>
Type: Object</p>
<p>The simulated hosts which execute processes. Each field corresponds to a host configuration, with the field name being used as the network hostname.</p>
<p>Shadow assigns each host to a node in the <a href="shadow/network_config.html">network topology</a>.</p>
<h4 id="hostshostnamebandwidth_down"><a class="header" href="#hostshostnamebandwidth_down"><code>hosts.&lt;hostname&gt;.bandwidth_down</code></a></h4>
<p>Default: null<br />
Type: String OR Integer OR null</p>
<p>Downstream bandwidth capacity of the host.</p>
<p>Overrides any default bandwidth values set in the assigned network topology node.</p>
<h4 id="hostshostnamebandwidth_up"><a class="header" href="#hostshostnamebandwidth_up"><code>hosts.&lt;hostname&gt;.bandwidth_up</code></a></h4>
<p>Default: null<br />
Type: String OR Integer OR null</p>
<p>Upstream bandwidth capacity of the host.</p>
<p>Overrides any default bandwidth values set in the assigned network topology node.</p>
<h4 id="hostshostnameoptions"><a class="header" href="#hostshostnameoptions"><code>hosts.&lt;hostname&gt;.options</code></a></h4>
<p>See <a href="shadow/shadow_config.html#host_defaults"><code>host_defaults</code></a>.</p>
<h4 id="hostshostnamequantity"><a class="header" href="#hostshostnamequantity"><code>hosts.&lt;hostname&gt;.quantity</code></a></h4>
<p>Default: 1<br />
Type: Integer</p>
<p>Number of hosts to start.</p>
<p>If quantity is greater than 1, each host's hostname will be suffixed with a counter. For example, a host with an id of <code>host</code> and quantity of 2 would produce nodes with hostnames <code>host1</code> and <code>host2</code>.</p>
<h4 id="hostshostnameprocesses"><a class="header" href="#hostshostnameprocesses"><code>hosts.&lt;hostname&gt;.processes</code></a></h4>
<p><em>Required</em><br />
Type: Array</p>
<p>Virtual software processes that the host will run.</p>
<h4 id="hostshostnameprocessesargs"><a class="header" href="#hostshostnameprocessesargs"><code>hosts.&lt;hostname&gt;.processes[*].args</code></a></h4>
<p>Default: &quot;&quot;<br />
Type: String OR Array of String</p>
<p>Process arguments.</p>
<h4 id="hostshostnameprocessesenvironment"><a class="header" href="#hostshostnameprocessesenvironment"><code>hosts.&lt;hostname&gt;.processes[*].environment</code></a></h4>
<p>Default: &quot;&quot;<br />
Type: String</p>
<p>Environment variables passed when executing this process. Multiple variables can be specified by using a semicolon separator (ex: <code>ENV_A=1;ENV_B=2</code>).</p>
<h4 id="hostshostnameprocessespath"><a class="header" href="#hostshostnameprocessespath"><code>hosts.&lt;hostname&gt;.processes[*].path</code></a></h4>
<p><em>Required</em><br />
Type: String</p>
<p>If the path begins with <code>~/</code>, it will be considered relative to the current user's home directory.</p>
<h4 id="hostshostnameprocessesquantity"><a class="header" href="#hostshostnameprocessesquantity"><code>hosts.&lt;hostname&gt;.processes[*].quantity</code></a></h4>
<p>Default: 1<br />
Type: Integer</p>
<p>The number of replicas of this process to execute.</p>
<h4 id="hostshostnameprocessesstart_time"><a class="header" href="#hostshostnameprocessesstart_time"><code>hosts.&lt;hostname&gt;.processes[*].start_time</code></a></h4>
<p>Default: &quot;0 sec&quot;<br />
Type: String OR Integer</p>
<p>The simulated time at which to execute the process.</p>
<h4 id="hostshostnameprocessesstop_time"><a class="header" href="#hostshostnameprocessesstop_time"><code>hosts.&lt;hostname&gt;.processes[*].stop_time</code></a></h4>
<p>Default: null<br />
Type: String OR Integer OR null</p>
<p>The simulated time at which to send a SIGKILL signal to the process.</p>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h3 id="network-graph-overview"><a class="header" href="#network-graph-overview">Network Graph Overview</a></h3>
<p>Processes running in Shadow do not have access to the internet; instead, processes running on Shadow virtual hosts utilize an internal routing module to communicate with other processes running on other virtual hosts in the simulation. The routing module is used to position virtual hosts within a network topology, to compute communication paths between virtual hosts, and to enforce network path characteristics like latency and packet loss.</p>
<p>Importantly, the routing module is currently used to <em>model</em> the performance characteristics of internet paths; we do not <em>simulate</em> the behavior of network routers (we do not run routing protocols like <a href="https://en.wikipedia.org/wiki/Border_Gateway_Protocol">BGP</a>).</p>
<p>This page describes the routing module and how it can be configured.</p>
<h4 id="graph"><a class="header" href="#graph">Graph</a></h4>
<p>Shadow represents a network topology over which processes can communicate using a <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">weighted graph</a>. The graph contains <em>vertices</em> that abstractly represent network locations, and <em>edges</em> representing network paths between those locations. Shadow requires that the graph is <a href="https://en.wikipedia.org/wiki/Connectivity_(graph_theory)">connected</a> such that there exists at least one <em>path</em> (a series of one or more edges) between every pair of vertices.</p>
<h4 id="behavior"><a class="header" href="#behavior">Behavior</a></h4>
<p>The graph encodes network positioning and path characteristics as attributes on the vertices and edges. Shadow uses the connectivity graph along with the information encoded in vertex and edge attributes to:</p>
<ul>
<li>attach virtual hosts to specific vertices (i.e., locations) in the network topology;</li>
<li>assign the bandwidth allowed for each attached virtual host;</li>
<li>compute the shortest path (weighted by edge <code>latency</code>) between two virtual hosts using <a href="https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm">Dijkstra's algorithm</a>; and</li>
<li>compute the end-to-end latency and packet loss for the shortest path.</li>
</ul>
<p>The bandwidth of the virtual hosts and the end-to-end latency and packet loss for a shortest path between two virtual hosts are then enforced for all network communication.</p>
<h4 id="important-notes"><a class="header" href="#important-notes">Important Notes</a></h4>
<ul>
<li>The network graph may be directed or undirected, as long as the graph is structured such that every vertex can reach every other vertex through a series of edges.</li>
<li>If the network graph is a <a href="https://en.wikipedia.org/wiki/Complete_graph">complete graph</a> (there exists a single unique edge between every pair of vertices), then we can avoid running the shortest path algorithm as a performance optimization by setting the <a href="shadow/shadow_config.html#networkuse_shortest_path">use_shortest_path option</a> to <code>False</code>.</li>
</ul>
<h3 id="network-graph-attributes"><a class="header" href="#network-graph-attributes">Network Graph Attributes</a></h3>
<p>We encode attributes on the vertices and edges that allow for configuring the simulated network characteristics. The attributes and their effect on the simulated network are described in more detail (alongside a simple example graph) on <a href="shadow/network_graph_attributes.html">the network graph attributes page</a>.</p>
<h3 id="using-an-existing-graph"><a class="header" href="#using-an-existing-graph">Using an Existing Graph</a></h3>
<p>We created a large network graph representing worldwide latencies and bandwidths as of 2018 using the <a href="https://atlas.ripe.net">RIPE Atlas measurement platform</a>. The graph contains network bandwidths and latencies in and between major cities around the world, and is suitable for general usage for most types of Shadow simualtions. The graph is <a href="https://tmodel-ccs2018.github.io/data/shadow/network/atlas-lossless.201801.shadow113.graphml.xml.xz">available for download as a research artifact</a> and more details about the measurement methodology is available on <a href="https://tmodel-ccs2018.github.io">the research artifacts site</a>.</p>
<p>Note: <a href="http://github.com/shadow/atlas">the scripts we used to create the graph</a> are also available, but are not recommended for general use. The scripts require advanced knowledge of RIPE Atlas and also require that you possess RIPE Atlas credits to conduct the measurements needed to create a new graph. We recommend using our existing graph linked above instead, which we may periodically update.</p>
<h3 id="creating-your-own-graph"><a class="header" href="#creating-your-own-graph">Creating Your Own Graph</a></h3>
<p>The python module <a href="http://networkx.github.io/">networkx</a> can be used to create and manipulate more complicated graphs.</p>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h3 id="network-graph-attributes-1"><a class="header" href="#network-graph-attributes-1">Network Graph Attributes</a></h3>
<p>The <a href="shadow/network_config.html">network graph overview</a> provides a general summary of Shadow's use of a network graph to abstractly model network position and to connect virtual hosts in a network topology while enforcing network characteristics on paths between hosts. This page describes the specific attributes that can be configured in the network graph, and the effect that each attribute has on the simulation.</p>
<h3 id="example-graph"><a class="header" href="#example-graph">Example Graph</a></h3>
<p>Below is an example of a simple network graph in the Shadow-supported GML format (note that GML calls <em>vertices</em> as <em>nodes</em>).</p>
<pre><code class="language-gml">graph [
  directed 0
  node [
    id 0
    label &quot;node at 1.2.3.4&quot;
    country_code &quot;US&quot;
    city_code &quot;Portland&quot;
    ip_address &quot;1.2.3.4&quot;
    bandwidth_down &quot;100 Mbit&quot;
    bandwidth_up &quot;100 Mbit&quot;
  ]
  edge [
    source 0
    target 0
    label &quot;path from 1.2.3.4 to 1.2.3.4&quot;
    latency 10.0
    jitter 0.0
    packet_loss 0.0
  ]
]
</code></pre>
<h3 id="configurable-attributes"><a class="header" href="#configurable-attributes">Configurable Attributes</a></h3>
<ul>
<li><a href="shadow/network_graph_attributes.html#graphdirected"><code>graph.directed</code></a></li>
<li><a href="shadow/network_graph_attributes.html#vertexid"><code>vertex.id</code></a></li>
<li><a href="shadow/network_graph_attributes.html#vertexlabel"><code>vertex.label</code></a></li>
<li><a href="shadow/network_graph_attributes.html#vertexcountry_code"><code>vertex.country_code</code></a></li>
<li><a href="shadow/network_graph_attributes.html#vertexcity_code"><code>vertex.city_code</code></a></li>
<li><a href="shadow/network_graph_attributes.html#vertexip_address"><code>vertex.ip_address</code></a></li>
<li><a href="shadow/network_graph_attributes.html#vertexbandwidth_down"><code>vertex.bandwidth_down</code></a></li>
<li><a href="shadow/network_graph_attributes.html#vertexbandwidth_up"><code>vertex.bandwidth_up</code></a></li>
<li><a href="shadow/network_graph_attributes.html#edgesource"><code>edge.source</code></a></li>
<li><a href="shadow/network_graph_attributes.html#edgetarget"><code>edge.target</code></a></li>
<li><a href="shadow/network_graph_attributes.html#edgelabel"><code>edge.label</code></a></li>
<li><a href="shadow/network_graph_attributes.html#edgelatency"><code>edge.latency</code></a></li>
<li><a href="shadow/network_graph_attributes.html#edgejitter"><code>edge.jitter</code></a></li>
<li><a href="shadow/network_graph_attributes.html#edgepacket_loss"><code>edge.packet_loss</code></a></li>
</ul>
<h4 id="graphdirected"><a class="header" href="#graphdirected"><code>graph.directed</code></a></h4>
<p>Required: False<br />
Default: <code>0</code><br />
Type: Integer</p>
<p>Specifies the symmetry of the edges in the graph. If set to <code>0</code> (the default), the graph is an <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">undirected graph</a>: an edge between vertex <code>u</code> and vertex <code>v</code> is symmetric and can be used to construct a path both from <code>u</code> to <code>v</code> and from <code>v</code> to <code>u</code>. If set to <code>1</code>, the graph is a <a href="https://en.wikipedia.org/wiki/Directed_graph">directed graph</a>: an edge from vertex <code>u</code> to vertex <code>v</code> is assymmetric and can only be used to construct a path from <code>u</code> to <code>v</code> (a separate edge from <code>v</code> to <code>u</code> must be specified to compose a path in the reverse direction).</p>
<h4 id="vertexid"><a class="header" href="#vertexid"><code>vertex.id</code></a></h4>
<p>Required: True<br />
Type: Integer</p>
<p>A unique integer identifier for a given vertex.</p>
<h4 id="vertexlabel"><a class="header" href="#vertexlabel"><code>vertex.label</code></a></h4>
<p>Required: False<br />
Default: n/a<br />
Type: String</p>
<p>An optional, human-meaningful string description of the vertex. The string may be used in log messages printed by Shadow.</p>
<h4 id="vertexcountry_code"><a class="header" href="#vertexcountry_code"><code>vertex.country_code</code></a></h4>
<p>Required: False<br />
Default: n/a<br />
Type: String</p>
<p>A code for the country in which the node represented by this vertex is located. This code can be used to control the placement of hosts in the network: when attaching a specific host into the network, we ignore any vertex whose <code>country_code</code> does not match the host's <a href="shadow/shadow_config.html#host_defaultscountry_code_hint"><code>country_code_hint</code> host configuration value</a> (if one is configured).</p>
<h4 id="vertexcity_code"><a class="header" href="#vertexcity_code"><code>vertex.city_code</code></a></h4>
<p>Required: False<br />
Default: n/a<br />
Type: String</p>
<p>A code for the city in which the node represented by this vertex is located. This code can be used to control the placement of hosts in the network: when attaching a specific host into the network, we ignore any vertex whose <code>city_code</code> does not match the host's <a href="shadow/shadow_config.html#host_defaultscity_code_hint"><code>city_code_hint</code> host configuration value</a> (if one is configured).</p>
<h4 id="vertexip_address"><a class="header" href="#vertexip_address"><code>vertex.ip_address</code></a></h4>
<p>Required: False<br />
Default: n/a
Type: String</p>
<p>An IP address at which the node represented by this vertex is located. This address can be used to control the placement of hosts in the network: after filtering vertices based on the city and country codes (as described above), we perform a <a href="https://en.wikipedia.org/wiki/Longest_prefix_match">longest prefix match</a> on the remaining vertices by comparing the vertex <code>ip_address</code> with the host's <a href="shadow/shadow_config.html#host_defaultsip_address_hint"><code>ip_address_hint</code> host configuration value</a> (if one is configured) and attach the host to the vertex with the closest match. We assign the host the address specified in <code>ip_address_hint</code> as long as that address has not yet been assigned to another host, otherwise we choose a unique address nearby to the requested address.</p>
<h4 id="vertexbandwidth_down"><a class="header" href="#vertexbandwidth_down"><code>vertex.bandwidth_down</code></a></h4>
<p>Required: True<br />
Type: String</p>
<p>A string defining the downstream (receive) bandwidth that will be allowed for any host attached to this vertex. Hosts may individually override this value in <a href="shadow/shadow_config.html#hostshostnamebandwidth_down">the Shadow config file</a>. The format of the string specifies the bandwidth and its unit as described in the <a href="shadow/shadow_config.html">config documentation</a>, e.g., <code>10 Mbit</code>. Note that this bandwidth is allowed for every host that is attached to this vertex; it is <strong>not</strong> the total bandwidth logically available at the node (which is not defined).</p>
<h4 id="vertexbandwidth_up"><a class="header" href="#vertexbandwidth_up"><code>vertex.bandwidth_up</code></a></h4>
<p>Required: True<br />
Type: String</p>
<p>A string defining the upstream (send) bandwidth that will be allowed for any host attached to this vertex. Hosts may individually override this value in <a href="shadow/shadow_config.html#hostshostnamebandwidth_up">the Shadow config file</a>. The format of the string specifies the bandwidth and its unit as described in the <a href="shadow/shadow_config.html">config documentation</a>, e.g., <code>10 Mbit</code>. Note that this bandwidth is allowed for every host that is attached to this vertex; it is <strong>not</strong> the total bandwidth logically available at the node (which is not defined).</p>
<h4 id="edgesource"><a class="header" href="#edgesource"><code>edge.source</code></a></h4>
<p>Required: True<br />
Type: Integer</p>
<p>The unique integer identifier of the first of two vertices of the edge. The vertex must exist in the graph. If the graph is directed, this vertex is treated as the source or start of the edge.</p>
<h4 id="edgetarget"><a class="header" href="#edgetarget"><code>edge.target</code></a></h4>
<p>Required: True<br />
Type: Integer</p>
<p>The unique integer identifier of the second of two vertices of the edge. The vertex must exist in the graph. If the graph is directed, this vertex is treated as the target or end of the edge.</p>
<h4 id="edgelabel"><a class="header" href="#edgelabel"><code>edge.label</code></a></h4>
<p>Required: False<br />
Default: n/a<br />
Type: String</p>
<p>An optional, human-meaningful string description of the edge. The string may be used in log messages printed by Shadow.</p>
<h4 id="edgelatency"><a class="header" href="#edgelatency"><code>edge.latency</code></a></h4>
<p>Required: True<br />
Type: Float</p>
<p>The latency that will be added to packets traversing this edge. This value is used as a weight while running Dijkstra's shortest path algorithm.</p>
<h4 id="edgejitter"><a class="header" href="#edgejitter"><code>edge.jitter</code></a></h4>
<p>Required: False<br />
Default: n/a<br />
Type: Float</p>
<p>This keyword is allowed but currently nonfunctional; it is reserved for future use.</p>
<h4 id="edgepacket_loss"><a class="header" href="#edgepacket_loss"><code>edge.packet_loss</code></a></h4>
<p>Required: True<br />
Type: Float</p>
<p>A fractional value between 0 and 1 representing the chance that a packet traversing this edge will get dropped.</p>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="building-the-c-rust-bindings"><a class="header" href="#building-the-c-rust-bindings">Building the C-Rust bindings</a></h2>
<p>When required, you can rebuild all of the C-Rust bindings by running:</p>
<pre><code class="language-bash">cd build &amp;&amp; cmake --target bindings .. &amp;&amp; make bindings
</code></pre>
<p>To see the specific options/flags provided to bindgen and cbindgen, you can use <code>make VERBOSE=1 bindings</code>.</p>
<p>Since the C bindings and Rust bindings rely on each other, you may sometimes need to build the bindings in a specific order. Instead of <code>make bindings</code>, you can be more specific using for example <code>make bindings_main_rust</code> to make the Rust bindings for <code>src/main</code>.</p>
<p>You may need to install bindgen, cbindgen, and clang:</p>
<pre><code class="language-bash">apt install -y clang
cargo install --force --version 0.18.0 cbindgen
cargo install --force --version 0.57.0 bindgen
</code></pre>
<p>The versions of bindgen and cbindgen you install should match the <a href="https://github.com/shadow/shadow/blob/dev/.github/workflows/lint.yml">versions installed in the CI</a>.</p>
<h2 id="extra-tests"><a class="header" href="#extra-tests">Extra tests</a></h2>
<p>Shadow includes tests that require additional dependencies, such as Tor, TGen, and networkx. These aren't run by default, but are run as part of the CI tests. To run them locally, first make sure that both tor and tgen are located at <code>~/.shadow/bin/{tor,tgen}</code>. These can be symlinks to tor and tgen binaries elsewhere in the filesystem. You should also install all of Shadow's optional dependencies.</p>
<p>It is recommended to build Shadow in release mode, otherwise the Tor tests may not complete before the timeout.</p>
<pre><code class="language-bash">./setup test -- --build-config extra
# To exclude the Tor tests (for example if you built Shadow in debug mode)
./setup test -- --build-config extra --label-exclude tor
</code></pre>
<p>If you change the version of tor located at <code>~/.shadow/bin/tor</code>, make sure to re-run <code>./setup build --test</code>.</p>
<h2 id="debugging"><a class="header" href="#debugging">Debugging</a></h2>
<h3 id="debugging-shadow-using-gdb"><a class="header" href="#debugging-shadow-using-gdb">Debugging Shadow using GDB</a></h3>
<p>When debugging, it will be helpful to use the Shadow option <code>--cpu-threshold=-1</code>. It disables the automatic virtual CPU delay measurement feature. This feature may introduce non-deterministic behaviors, even when running the exact same experiment twice, by the re-ordering of events that occurs due to how the kernel schedules the physical CPU of the experiment machine. Disabling the feature with the above option will ensure a deterministic experiment, making debugging easier.</p>
<p>Build Shadow with debugging symbols by using the <code>-g</code> flag. See the help menu with <code>./setup build --help</code>.</p>
<p>These days, shadow can typically be run directly from gdb:</p>
<pre><code>gdb shadow
&gt; run shadow.config.xml
</code></pre>
<p>An alternative is to run shadow with the <code>-g</code> flag, which will pause shadow after startup and print the <code>PID</code>. You can then simply attach gdb to shadow in a new terminal and continue the experiment:</p>
<pre><code>shadow -g shadow.config.xml
# new terminal
gdb --pid=PID
&gt; continue
</code></pre>
<h4 id="debugging-plugins-with-gdb"><a class="header" href="#debugging-plugins-with-gdb">Debugging plugins with gdb</a></h4>
<p>If debugging plugins in shadow instead of shadow itself, some extra commands are helpful. Because of performance problems in gdb, shadow (via elf-loader) prevents debug symbols for plugins from loading by default. (Note: The following commands include <code>set scheduler-locking on</code> to prevent gdb from running other threads while executing the requested command. This should not be done until needed and should be turned back off if you wish to run Shadow again or from the current state.) To load all debug symbols in gdb, stop the experiment after the relevant plugins have been loaded, then run:</p>
<pre><code>&gt; set scheduler-locking on
&gt; p vdl_linkmap_abi_update()
&gt; set scheduler-locking off
</code></pre>
<p>However, unless the experiment is very small, this will take too long to feasibly run. Instead, individual plugins can have their debug symbols loaded by calling:</p>
<pre><code>&gt; set scheduler-locking on
&gt; p vdl_linkmap_abi_from_addr(addr)
&gt; set scheduler-locking off
</code></pre>
<p>where <code>addr</code> is an address in a loaded elf file, e.g. from a backtrace.
This process can be automated in gdb by copying and pasting the commands below into gdb before running/continuing:</p>
<pre><code>py
def bt_load():
  frame=gdb.newest_frame()
  frameaddrs=&quot;&quot;
  count=0
  while(frame):
    frameaddrs += &quot;, &quot; + (str(frame.pc()))
    count += 1
    frame=frame.older()
  command = &quot;p vdl_linkmap_abi_from_addrs(&quot; + str(count) + frameaddrs + &quot;)&quot;
  gdb.execute(command)
end
catch signal SIGILL SIGFPE SIGSEGV SIGSYS
commands
set scheduler-locking on
py bt_load()
end
</code></pre>
<p>where the above catches any of <code>SIGILL SIGFPE SIGSEGV SIGSYS</code> (illegal instructions, arithmetic errors, segfaults, and improper syscalls) and loads the debug symbols from every file in the backtrace. You can also load the debug symbols from the current backtrace yourself by running <code>py bt_load()</code> if you define it as above.</p>
<p>Some other functions elf-loader provides that could potentially be useful are:</p>
<ul>
<li><code>vdl_linkmap_shadow_print()</code><br />
prints all shared object files in all namespaces for which we can load debug symbols, and</li>
<li><code>vdl_linkmap_abi_print()</code><br />
prints all shared ojbect files in all namespaces that should already have their debug symbols loaded by gdb.</li>
</ul>
<h3 id="tracing-shadow-using-valgrind"><a class="header" href="#tracing-shadow-using-valgrind">Tracing Shadow using Valgrind</a></h3>
<p>If you want to be able to run Shadow through valgrind and the application you 
are running in Shadow uses OpenSSL (i.e. the Scallion plug-in), you should configure OpenSSL with the 
additional option: <code>-DPURIFY</code>. This fixes OpenSSL so it doesn't break valgrind.
You may also want to ensure that debugging symbols are included in the GLib
that Shadow links to, and any library used by the plug-in. This can be achieved
with the compiler flag <code>-g</code> when manually building a local version of GLib.</p>
<h3 id="profiling-shadow"><a class="header" href="#profiling-shadow">Profiling Shadow</a></h3>
<h4 id="profiling-with-gprof"><a class="header" href="#profiling-with-gprof">Profiling with <code>gprof</code></a></h4>
<p>This method only provides profiling info for the core of Shadow, not for elf-loader, plug-ins, or other libraries. Also, the profiling info is limited since gprof only measures active CPU usage and function call counts and misses performance related to blocking IO and barrier waits.</p>
<pre><code class="language-bash">./setup build -cgo
./setup install
cd resource/examples
shadow shadow.config.xml &gt; shadow.log
gprof `which shadow` gmon.out &gt; analysis.txt
less analysis.txt
</code></pre>
<h4 id="profiling-with-perf"><a class="header" href="#profiling-with-perf">Profiling with <code>perf</code></a></h4>
<p>Either run perf when starting Shadow:</p>
<pre><code class="language-bash">perf record shadow shadow.config.xml &gt; shadow.log
</code></pre>
<p>Or, connect to a running Shadow process:</p>
<pre><code class="language-bash">perf record -p &lt;PID&gt;
</code></pre>
<p>Either of the above two options will write a <code>perf.data</code> file when you press control-c, or Shadow ends. You can then analyze the report:</p>
<pre><code class="language-bash">perf report
</code></pre>
<p>Perf is extremely powerful with many options. See <code>man perf</code> or <a href="https://perf.wiki.kernel.org/index.php/Tutorial">the perf wiki</a> for more info.</p>
<p>Note that any time an example uses the <code>-g</code> option in <code>perf record</code>, you should use <code>--call-graph dwarf</code> instead. (The <code>-g</code> option defaults to stack frames for traces, which elf-loader and certain optimizations can break. If you see absurdly tall or small call graphs, this is probably what happened.)</p>
<h3 id="testing-for-deterministic-behavior"><a class="header" href="#testing-for-deterministic-behavior">Testing for Deterministic Behavior</a></h3>
<p>If you run Shadow twice with the same seed (the <code>-s</code> or <code>--seed</code> command line options), then it <em>should</em> produce deterministic results (it's a bug if it doesn't).</p>
<p>A good way to check this is to compare the log output of an application that was run in Shadow. For example, after running two TGen experiments where the results are in the <code>shadow.data.1</code> and <code>shadow.data.2</code> directories, you could run something like the following bash script:</p>
<pre><code class="language-bash">#!/bin/bash

found_difference=0

for SUFFIX in \
    hosts/fileserver/stdout-fileserver.tgen.1000.log \
    hosts/client/stdout-client.tgen.1000.log
do
    ## ignore memory addresses in log file with `sed 's/0x[0-9a-f]*/HEX/g' FILENAME`
    sed -i 's/0x[0-9a-f]*/HEX/g' shadow.data.1/${SUFFIX}
    sed -i 's/0x[0-9a-f]*/HEX/g' shadow.data.2/${SUFFIX}

    diff --brief shadow.data.1/${SUFFIX} shadow.data.2/${SUFFIX}
    exit_code=$?

    if (($exit_code != 0)); then
      found_difference=1
    fi
done

if (($found_difference == 1)); then
  echo -e &quot;\033[0;31mDetected difference in output (Shadow may be non-deterministic).\033[0m&quot;
else
  echo -e &quot;\033[0;32mDid not detect difference in Shadow output (Shadow may be deterministic).\033[0m&quot;
fi
</code></pre>
<p>If you find non-deterministic behavior in your Shadow experiment, please consider helping to diagnose the problem by opening a <a href="https://github.com/shadow/shadow/issues/new">new issue</a>.</p>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="continuous-integration-tests"><a class="header" href="#continuous-integration-tests">Continuous integration tests</a></h2>
<h3 id="on-github"><a class="header" href="#on-github">On GitHub</a></h3>
<p>Our continuous integration tests build and test Shadow on every supported
platform and configuration. GitHub runs these tests automatically when making
or modifying a pull request, in the <a href="shadow/../.github/workflows/build_shadow.yml">build and test
workflow</a>. Pull requests without passing
integration tests are blocked from merging.</p>
<h3 id="running-locally"><a class="header" href="#running-locally">Running locally</a></h3>
<p>We also have scripts for running the continuous integration tests locally,
inside Docker containers. This can be useful for debugging and for quickly
iterating on a test that's failing in GitHub's test runs.</p>
<p>The <a href="shadow/../ci/run.sh"><code>run.sh</code></a> script builds a Docker images for all
supported configurations, and runs our tests in them.</p>
<p>On the first invocation you should tell the <code>run.sh</code> script to build the images
using <code>-i</code>:</p>
<pre><code class="language-{.bash}">sudo ci/run.sh -i
</code></pre>
<p>If you wish to only check whether the tests pass or fail, future invocations
can omit the <code>-i</code> option to use the existing image and build/test only the
incremental changes. None of the test results will be saved in this case, but
it is much quicker to build.</p>
<p>Note that building all images locally typically takes hours. More often,
you'll want to only run some smaller set of configurations locally.
To run only the configurations you specify, use the <code>-o</code> flag:</p>
<pre><code class="language-{.bash}">sudo ci/run.sh -i -o &quot;ubuntu:18.04;clang;debug fedora:33;gcc;release&quot;
</code></pre>
<p>For additional options, run <code>ci/run.sh -h</code>.</p>
<h3 id="debugging-locally"><a class="header" href="#debugging-locally">Debugging locally</a></h3>
<p>After a local run fails, you can use Docker to help debug it. If you previously
ran the tests without the <code>-i</code> option, re-run with the <code>-i</code> option to rebuild
the Docker image(s). If Shadow was built successfully and the failure happened
at the testing step, then the Docker image was built and tagged, and you can
run an interactive shell in a container built from that image.</p>
<p>e.g.:</p>
<pre><code class="language-{.bash}">sudo docker run --shm-size=1g -it shadow:centos-8-clang-debug /bin/bash
</code></pre>
<p>If the failure happened in the middle of building the Docker image, you can do
the same with the last intermediate layer that was built successfully. e.g.
given the output:</p>
<pre><code class="language-{.bash}">$ sudo ci/run.sh -i -o &quot;centos:8;clang;debug&quot;
&lt;snip&gt;
Step 13/13 : RUN . ci/container_scripts/build_and_install.sh
 ---&gt; Running in a11c4a554ef8
&lt;snip&gt;
    516 [ERROR] Non - zero return code from make.
</code></pre>
<p>You can start a container from the image where Docker tried (and failed) to run
<code>ci/the build_and_install.sh</code> script was executed with:</p>
<pre><code class="language-{.bash}">sudo docker run --shm-size=1g -it a11c4a554ef8 /bin/bash
</code></pre>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h1 id="using-a-recompiled-libc"><a class="header" href="#using-a-recompiled-libc">Using a recompiled libc</a></h1>
<p>With a stock libc library, it's difficult to interpose every syscall via
<code>LD_PRELOAD</code>. Once code is executing inside a libc function such as <code>fwrite</code>,
it typically makes non-PLT calls and uses inline assembly to make system calls,
leaving no opportunity to intercept the system call itself via <code>LD_PRELOAD</code>.
For more about this problem see
<a href="https://www.jimnewsome.net/posts/interposing-internal-libc-calls/">https://www.jimnewsome.net/posts/interposing-internal-libc-calls/</a>.</p>
<p>One solution is to use <code>ptrace</code> instead, which can be done in shadow using
<code>--interpose-method=ptrace</code>. This approach can have some drawbacks though, such
as not being able to attach to the child process with gdb at runtime.</p>
<p>Another solution is to reimplement every entry point into libc, including
reimplementing e.g. <code>fwrite</code>, to ensure that they internally end up calling
Shadow's syscall implementation. For complete coverage of libc though, this
ends up requiring reimplementing a substantial chunk of the library. Shadow
does this for some of libc, but currently has some gaps, and probably always
will.</p>
<p>We can greatly improve our coverage of the libc API by patching a full
implementation of libc to make system calls via an interposable call to the
<code>syscall</code> function rather than using the <code>syscall</code> instruction inline. Then in
the Shadow shim we only need to interpose the <code>syscall</code> function.  For more
about how this works, and a proof of concept, see
<a href="https://www.jimnewsome.net/posts/patching-glibc-to-make-syscalls-interposable/">https://www.jimnewsome.net/posts/patching-glibc-to-make-syscalls-interposable/</a>.</p>
<p>For this to work reliably though, we have to be careful that our libc is
compatible with the system's libc headers. Therefore what we actually want to
do is patch the libc source from our system's package manager, and configure
and compile it with the same options that were used with the system's packaged
libc.</p>
<h2 id="compiling-on-ubuntu-1804"><a class="header" href="#compiling-on-ubuntu-1804">Compiling on Ubuntu 18.04</a></h2>
<ul>
<li>Enable source repos in <code>/etc/apt/sources.list</code></li>
<li>Run <code>apt source glibc-source</code> to get the system's glibc source.</li>
<li>Patch it (see below).</li>
<li>Run <code>dpkg-source --commit</code> to locally &quot;commit&quot; the patch.</li>
<li>Run <code>dpkg-buildpackage</code> to build the patched source along with Ubuntu's
additional patches and configuration options. For me this fails in testing,
but still produces the library binaries.</li>
</ul>
<p>To patch the source:</p>
<pre><code class="language-shell"># Save the source directory for future reference. Your version number may
# be different.
cd glibc-2.27
SYSTEM_LIBC_SOURCE=`pwd`

# Grab the patched glibc. This has to be outside of SYSTEM_LIBC_SOURCE.
cd ..
git clone https://github.com/sporksmith/glibc.git interposable-glibc
cd interposable-glibc

# Switch to the patched branch. interpose-syscalls-2.27 is based on 2.27.
# interpose-syscalls is baed on 2.31 (dev).
git checkout origin/interpose-syscalls-2.27

# Generate patches
git format-patch glibc-2.27

# Apply the patches
cd $SYSTEM_LIBC_SOURCE
patch -p1 ../interposable-glibc/*.patch
</code></pre>
<h2 id="compiling-on-centos-7"><a class="header" href="#compiling-on-centos-7">Compiling on CentOS 7</a></h2>
<p>Install prerequisites:</p>
<pre><code class="language-shell">sudo yum install -y \
    gcc \
    git \
    make \
    redhat-rpm-config \
    rpm-build
sudo yum-builddep -y glibc
</code></pre>
<p>Set up rpm build environment, following
<a href="https://wiki.centos.org/HowTos/SetupRpmBuildEnvironment">https://wiki.centos.org/HowTos/SetupRpmBuildEnvironment</a>:</p>
<pre><code class="language-shell">mkdir -p ~/rpmbuild/{BUILD,RPMS,SOURCES,SPECS,SRPMS}
echo '%_topdir %(echo $HOME)/rpmbuild' &gt; ~/.rpmmacros
</code></pre>
<p>Get and unpack centos7's glibc package:</p>
<pre><code class="language-shell">cd ~ &amp;&amp; yumdownloader --source glibc
cd ~ &amp;&amp; rpm -ivh glibc-2.17-307.el7.1.src.rpm
</code></pre>
<p>Get custom patched source, and use it to generate the patch:</p>
<pre><code class="language-shell">cd ~ &amp;&amp; git clone --depth=2 -b interpose-syscalls-2.17-centos7 https://github.com/sporksmith/glibc.git
cd ~/glibc &amp;&amp; git diff glibc-2.17-centos7 &gt; ~/rpmbuild/SOURCES/use-syscall-function.patch
</code></pre>
<p>Next you'll need to edit <code>~/rpmbuild/SPECS/glibc.spec</code> file to tell it to apply the patch.
You'll need to add a line like:</p>
<pre><code>PatchNNNN: use-syscall-function.patch
</code></pre>
<p>and another like:</p>
<pre><code>%patchNNNN -p1
</code></pre>
<p>For more on editing the spec file, see <a href="https://blog.packagecloud.io/eng/2015/04/20/working-with-source-rpms/#modifying-the-source-and-applying-patches">https://blog.packagecloud.io/eng/2015/04/20/working-with-source-rpms/#modifying-the-source-and-applying-patches</a>.</p>
<pre><code class="language-shell"># (Re)unpack, patch, and build
cd ~/rpmbuild/SPECS &amp;&amp; rpmbuild -ba glibc.spec
</code></pre>
<h2 id="using-the-compiled-libc"><a class="header" href="#using-the-compiled-libc">Using the compiled libc</a></h2>
<p>Our patched libc can be injected via <code>LD_LIBRARY_PATH</code> or <code>LD_PRELOAD</code>.
I've been using <code>LD_LIBRARY_PATH</code> because there are actually multiple libraries
compiled, and we'll want those others to be preferred as well (e.g. <code>libpthread</code>).
In shadow's configuration file you can set the environment variable for all
loaded plugins with the <code>environment</code> attribute of the <code>shadow</code> tag. e.g.:</p>
<pre><code>&lt;shadow environment=&quot;LD_LIBRARY_PATH=/path/to/glibc-2.27/build-tree/amd64-libc&quot;&gt;
</code></pre>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="contributing"><a class="header" href="#contributing">Contributing</a></h2>
<p>For trivial fixes (e.g. fixing typos or bugs spanning only a few
lines), feel free to send a pull request with your changes.  For
anything bigger than that, it's best to talk to us first.</p>
<p>If you have a specific improvement you'd like to contribute to
Shadow, the best way to get started is to file an issue or comment on
an existing one. You can save wasted work this way by ensuring we
have agreement on whether you're planned improvement and design for
that improvement fits into the roadmap for Shadow, and won't conflict
with other on-going development.</p>
<p>If you haven't already, it's worth going through the <a href="shadow/README.html">general
documentation</a> to get started with building and using
Shadow.</p>
<p>When you're ready to start coding, please take a look at our <a href="shadow/coding_style.html">Coding
style</a> and <a href="shadow/pull_requests.html">pull request</a>
guidelines.</p>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="coding-style"><a class="header" href="#coding-style">Coding style</a></h2>
<h3 id="clang-format"><a class="header" href="#clang-format">Clang-format</a></h3>
<p>Our C code formatting style is defined in our
<a href="https://clang.llvm.org/docs/ClangFormat.html">clang-format</a> <a href="shadow/../.clang-format">configuration
file</a>. We try to avoid mass re-formatting, but generally any
lines you modify should be reformatted using <code>clang-format</code>.</p>
<p>To add Ctrl-k as a &quot;format region&quot; in visual and select modes of vim, add the
following to your .vimrc:</p>
<pre><code>vmap &lt;C-K&gt; :py3f /usr/share/vim/addons/syntax/clang-format.py&lt;cr&gt;
</code></pre>
<p>Alternatively you can use the
<a href="https://github.com/llvm-mirror/clang/blob/master/tools/clang-format/git-clang-format">git-clang-format</a>
tool on the command-line to modify the lines touched by your commits.</p>
<h3 id="rustfmt"><a class="header" href="#rustfmt">Rustfmt</a></h3>
<p>To format your Rust code, run <code>cargo fmt</code> once in each Rust crate that you
modify.</p>
<p>Examples:</p>
<pre><code class="language-bash">(cd src/main &amp;&amp; cargo fmt)
(cd src/test &amp;&amp; cargo fmt)
(cd src/support/logger/rust_bindings &amp;&amp; cargo fmt)
</code></pre>
<h3 id="including-headers"><a class="header" href="#including-headers">Including headers</a></h3>
<h4 id="which-headers-to-include"><a class="header" href="#which-headers-to-include">Which headers to include</a></h4>
<p>Every source and header file should directly include the headers that export
all referenced symbols and macros.</p>
<p>In a C file, includes should be broken into blocks, with the includes sorted
alphabetically within each block. The blocks should occur in this order:</p>
<ul>
<li>The C file's corresponding header; e.g. <code>foo.h</code> for <code>foo.c</code>. This enforces
that the header is self-contained; i.e. doesn't depend on other headers to
be included before it.</li>
<li>System headers are included next to minimize unintentionally exposing any
macros we define to them.</li>
<li>Any other necessary internal headers.</li>
</ul>
<p>This style is loosely based on that used in
<a href="https://wiki.gnome.org/Projects/GTK/BestPractices/GlibIncludes">glib</a> and
supported by the <a href="https://include-what-you-use.org/">include what you use</a>
tool.</p>
<h4 id="inclusion-style"><a class="header" href="#inclusion-style">Inclusion style</a></h4>
<p>Headers included from within the project should use quote-includes, and should
use paths relative to <code>src/</code>. e.g. <code>#include &quot;main/utility/byte_queue.h&quot;</code>, not
<code>#include &quot;byte_queue.h&quot;</code> (even from within the same directory), and not
<code>#include &lt;main/utility/byte_queue.h&gt;</code>.</p>
<p>Headers included external to this repository should use angle-bracket includes.
e.g. <code>#include &lt;glib.h&gt;</code>, not <code>#include &quot;glib.h&quot;</code>.</p>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="pull-requests-prs"><a class="header" href="#pull-requests-prs">Pull requests (PRs)</a></h2>
<h3 id="clean-commits"><a class="header" href="#clean-commits">Clean commits</a></h3>
<p>Ideally, every commit in history of the <code>main</code> branch should:</p>
<ul>
<li>Be a focused, self-contained change.</li>
<li>Have a commit message that summarizes the change and explains <em>why</em> the change
is being made, if not self-evident.</li>
<li>Build (<code>./setup build --test</code>).</li>
<li>Pass tests (<code>./setup test</code>).</li>
</ul>
<h3 id="drafting-a-pr"><a class="header" href="#drafting-a-pr">Drafting a PR</a></h3>
<p>PRs should be split into smaller, more focused, changes when feasible.
However, we also want to avoid polluting the history with commits that don't
build or pass tests, or commits within a single PR that fix a mistake earlier in
the PR. While iterating on the PR, the <code>--fixup</code> and
<code>--squash</code> flags are useful for committing changes that should ultimately be
merged with one of the earlier commits.</p>
<p>When creating a pull request, we suggest you first create it as a
<a href="https://github.blog/2019-02-14-introducing-draft-pull-requests/">draft</a>.  This
will still trigger our continuous-integration checks, and give you a chance
resolve any issues with those (i.e. broken tests) before requesting review.</p>
<p>Once done iterating, first consider using <code>git rebase -i --autosquash</code> to clean
up your commit history, and then force pushing to update your PR.  Finally, take
the pull request out of draft mode to signal that you're ready for review.</p>
<h3 id="responding-to-review-feedback"><a class="header" href="#responding-to-review-feedback">Responding to review feedback</a></h3>
<p><em>During</em> PR review, please do not rebase or force-push, since this makes it
difficult to see what's changed between rounds of review. Consider using
<code>--fixup</code> and <code>--squash</code> for commits responding to review feedback, so that they
can be appropriately squashed before the final merge. <a href="https://github.com/torbiak/git-autofixup/">git autofixup</a> can also be useful for generating
<code>--fixup</code> commits.</p>
<h3 id="merging"><a class="header" href="#merging">Merging</a></h3>
<p>When the PR is ready to be merged, the reviewer might ask you to <code>git rebase</code>
and force push to clean up history, or might do it themselves.</p>
<p>For the maintainer doing the merge:</p>
<p>If the PR is relatively small, or if it's not worth the effort of rewriting
history into clean commits, use the &quot;squash and merge&quot; strategy.</p>
<p>If the individual commits appear to be useful to keep around in our history,
instead use the &quot;create a merge commit&quot; strategy. There's no need to review
every individual commit when using this strategy, but if the intermediate
commits are obviously low quality consider using the &quot;squash and merge strategy&quot;
instead. Note that since this strategy creates a merge commit, we can still
later identify and filter out the intermediate commits if desired, e.g. with
<code>git log --first-parent main</code>.</p>
<p>We've disabled the &quot;Rebase and merge&quot; option, since it does a fast-forward
merge, which makes the intermediate commits indistingishuable from the validated
and reviewed final state of the PR.</p>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="maintainer-playbook"><a class="header" href="#maintainer-playbook">Maintainer playbook</a></h2>
<h3 id="tagging-shadow-releases"><a class="header" href="#tagging-shadow-releases">Tagging Shadow releases</a></h3>
<p>We use <a href="https://semver.org/">Semantic Versioning</a>, and increment version
numbers with the <a href="https://pypi.org/project/bumpversion/">bumpversion</a> tool.</p>
<p>The following commands can be used to tag a new version of Shadow, after which an
archive will be available on github's <a href="https://github.com/shadow/shadow/releases">releases page</a>.</p>
<pre><code class="language-bash">git checkout main

# Bump the patch, minor, or major version number, commit the change, and tag
# that commit.
bumpversion &lt;patch|minor|major&gt; --tag --commit

# Get the new version number.
VERSION=`awk -F &quot;=&quot; '/current_version/ {print $2}' .bumpversion.cfg | tr -d ' '`

# Push to GitHub.
git push origin v$VERSION
</code></pre>
<p>Our releases will then be tagged off of the main branch.</p>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h1 id="national-science-foundation-sponsorship"><a class="header" href="#national-science-foundation-sponsorship">National Science Foundation Sponsorship</a></h1>
<p><strong>Project Title:</strong> Expanding Research Frontiers with a Next-Generation Anonymous Communication Experimentation (ACE) Framework</p>
<p><strong>Project Period:</strong> October 1, 2019 - September 30, 2022</p>
<p><strong>Abstract:</strong> <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1925497">NSF Award Abstract #1925497</a></p>
<p>The goal of this project is to develop a scalable and mature deterministic network simulator, capable of quickly and accurately simulating large networks such as <a href="https://www.torproject.org">Tor</a>. This project builds on <a href="https://shadow.github.io/">the Shadow Simulator</a>.</p>
<h2 id="nsf-project-overview"><a class="header" href="#nsf-project-overview">NSF Project Overview</a></h2>
<p>ACE will be developed with the following features:</p>
<ul>
<li><strong>Application Emulation.</strong> Learning from the community’s experience, ACE will directly execute software and run applications as normal operating system processes. By supporting the general execution of applications (i.e., anything that can be executed as a process: network servers, web browsers, scripts, etc.), ACE will support software independent of the programming language chosen by developers, and ACE will maximize its applicability to a large range of evaluation approaches that CISE researchers choose to utilize. As a result, ACE will be well-suited to website fingerprinting and censorship circumvention research focus areas, which typically require running a variety of tools written in a variety of languages.</li>
<li><strong>Network Simulation.</strong> ACE will feature a light-weight network simulation component that will allow applications to communicate with each other through the ACE framework rather than over the Internet. ACE will simulate common transport protocols, such as TCP and UDP. ACE will also simulate virtual network routers and other network path components between end-hosts, and support evaluation under dynamic changes to timing, congestion, latency, bandwidth, network location, and network path elements. Therefore, ACE will support both network-aware and location-aware anonymous communication research and allow researchers to continue to advance this research agenda in current and future Internet architectures.</li>
<li><strong>Function Interposition.</strong> ACE will utilize function interposition in order to connect the processes being run by the operating system to the core network simulation component. ACE will support an API of common system calls that are used to, e.g., send and receive data to and from the network. Therefore, all processes executed in ACE will be isolated from the Internet and connected through ACE’s simulated network, and the simulation component will drive process execution.</li>
<li><strong>Controlled, Deterministic Execution.</strong> ACE features a deterministic discrete-event engine, and will therefore control time and operate in simulated timescales. As a result, ACE will be disconnected from the computational abilities of the host machine: ACE will run as-fast-as-possible, which could be faster or slower than real time depending on experiment load. ACE is deterministic so that research results can be independently and identically reproduced and verified across research labs.</li>
<li><strong>Parallel and Distributed Execution.</strong> ACE will rely on the operating system kernel to run and manage processes. Operating system kernels have been optimized for this task, and ACE will benefit in terms of better performance and a smaller code base. Moreover, ACE will be embarrassingly parallel: the Linux kernel generally scales to millions of processes that can be run in parallel, and we will design ACE such that any number of processes can be executed across multiple distinct machines. Therefore, ACE will scale to realistically-sized anonymous communication networks containing millions of nodes, and can be deployed on whatever existing infrastructure is available at community members' institutions.</li>
</ul>
<p>As part of the ACE framework, we will also develop a <strong>user interface</strong> to control and monitor the experimental process, a <strong>toolkit</strong> to help users set up and configure experiments (including network, mobility, and traffic characteristics and models) and to visualize results, and a <strong>data repository</strong> where researchers can share and archive experimental results.</p>
<h2 id="project-goalsactivities"><a class="header" href="#project-goalsactivities">Project Goals/Activities</a></h2>
<p>Here we outline some high level tasks that we are completing or plan to complete under this project. We are using Github for project development, including for tracking progress on major milestones and development tasks. We provide an outline of our agenda here, and link to the appropriate Github page where appropriate. Tasks without corresponding Github links means we don't yet have progress to share at this time.</p>
<ul>
<li>
<p><strong>Task 0: Investigate Architectural Improvements</strong></p>
<ul>
<li>Build prototype of a process-based simulation architecture - <a href="https://github.com/shadow/shadow/milestone/16">milestone</a></li>
<li>Evaluate and compare against a plugin-based simulation architecture</li>
<li>Decide which architecture is right for ACE</li>
</ul>
</li>
<li>
<p><strong>Task 1: Develop Core ACE System</strong></p>
<ul>
<li>Improve test coverage and infrastructure - <a href="https://github.com/shadow/shadow/milestone/15">shadow milestone</a>, <a href="https://github.com/shadow/shadow-plugin-tor/milestone/1">shadow-plugin-tor milestone</a></li>
<li>Enable new code to be written in Rust - <a href="https://github.com/shadow/shadow/milestone/17">milestone</a></li>
<li>Improve consistency of simulation options and configuration</li>
<li>Improve maintainability and accuracy of TCP implementation - <a href="https://github.com/shadow/shadow/milestone/18">milestone</a></li>
<li>Simplify event scheduler, implement continuous event execution model</li>
<li>Build a distributed core simulation engine</li>
<li>Develop CPU usage model to ensure plugin CPU utilization consumes simulation time</li>
</ul>
</li>
<li>
<p><strong>Task 2: Develop User Interface and Visualizations</strong></p>
<ul>
<li>Design control protocol and API for interacting with Shadow</li>
<li>Specify/document protocol</li>
<li>Develop user interface that uses the control API</li>
<li>Improve tools for analyzing and understanding simulation results</li>
</ul>
</li>
<li>
<p><strong>Task 3: Develop Simulation Models for ACE</strong></p>
<ul>
<li>Improve tools for generating and configuring private Tor networks</li>
<li>Improve tools for generating and configuring background traffic models</li>
<li>Improve tools for modeling Internet paths and latency</li>
<li>Develop support for mobile hosts</li>
<li>Create realistic host mobility models</li>
</ul>
</li>
<li>
<p><strong>Task 4: Engage Community</strong></p>
<ul>
<li>Create data repository where users can share configs and results</li>
<li>Create user outreach material and surveys to collect feedback</li>
<li>Improve user documentation and usage instructions</li>
</ul>
</li>
</ul>
<p>Over all tasks, we plan to significantly improve documentation, test coverage, and code maintainability.</p>
<h2 id="people"><a class="header" href="#people">People</a></h2>
<ul>
<li><a href="https://www.robgjansen.com">Rob Jansen</a> - Project Leader, Principal Investigator, U.S. Naval Research Laboratory</li>
<li>Roger Dingledine - Principal Investigator, The Tor Project</li>
<li>Micah Sherr - Principal Investigator, Georgetown University</li>
<li>Jim Newsome - Developer, The Tor Project</li>
<li>Steven Engler - Developer, Georgetown University / The Tor Project</li>
</ul>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="tgen"><a class="header" href="#tgen">TGen</a></h2>
<p><img src="https://github.com/shadow/tgen/workflows/Tests/badge.svg" alt="" /></p>
<p>TGen is a C application that generates traffic flows between other
TGen instances. The characteristics of the traffic (e.g., size, timing,
number of parallel flows, etc.) can be configured by the user.</p>
<p>TGen can generate complex traffic patterns. Users write relatively simple
python3 scripts to generate <code>graphml</code> files that are then used as TGen
configuration files that instruct TGen how to generate traffic. TGen also
supports the use of Markov models in order to generate TCP flows and packet
streams according to common probability distributions.</p>
<p>TGen is used to simulate traffic flows in <a href="https://github.com/shadow/shadow">Shadow</a>,
and to monitor Tor performance in <a href="https://gitweb.torproject.org/onionperf.git">OnionPerf</a>.</p>
<h2 id="setup"><a class="header" href="#setup">Setup</a></h2>
<p>Dependencies in Fedora/RedHat:</p>
<pre><code>sudo yum install cmake glib2 glib2-devel igraph igraph-devel
</code></pre>
<p>Dependencies in Ubuntu/Debian:</p>
<pre><code>sudo apt-get install cmake libglib2.0-0 libglib2.0-dev libigraph0v5 libigraph0-dev
</code></pre>
<p>Build with a custom install prefix:</p>
<pre><code>mkdir build &amp;&amp; cd build
cmake .. -DCMAKE_INSTALL_PREFIX=/home/$USER/.local
make
</code></pre>
<p>Optionally install to the prefix:</p>
<pre><code>make install
</code></pre>
<h2 id="usage"><a class="header" href="#usage">Usage</a></h2>
<p>Run TGen with a single argument (the path to a config file). For example,
first run a server:</p>
<pre><code>tgen resource/server.tgenrc.graphml &gt; tgen.server.log
</code></pre>
<p>and then run a client that connects to the server:</p>
<pre><code>tgen resource/client.tgenrc.graphml &gt; tgen.client.log
</code></pre>
<p>See the <a href="tgen/resource">resource/</a> directory for example config files.</p>
<h2 id="more-documentation"><a class="header" href="#more-documentation">More documentation</a></h2>
<p>See <a href="tgen/tools/README">tools/README</a> for setup instructions for
the TGenTools toolkit that can be used to parse and plot <code>tgen</code> log output.</p>
<p>See <a href="tgen/doc/TGen-Overview.html">doc/TGen-Overview.md</a> for an overview of how to use
a graph to instruct TGen how it should generate traffic, and then see
<a href="tgen/doc/TGen-Options.html">doc/TGen-Options.md</a> for a description of all options
supported by TGen.</p>
<p>See <a href="tgen/doc/TGen-Markov-Models.html">doc/TGen-Markov-Models.md</a> for a description
of how to create and use Markov models to instruct TGen how to generate
streams in a traffic flow and packets in a stream.</p>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h1 id="markov-models"><a class="header" href="#markov-models">Markov Models</a></h1>
<p>TGen supports the use of Markov models to allow the user to control how TCP
streams are created. TGen uses Markov models for three distinct processes:</p>
<ul>
<li>In a <strong>traffic</strong> action, a Markov model can be used to configure the flow
creation process, i.e., the frequency with which new flows should
be created. The Markov model specifies inter-flow delay distributions.
This model is configured with the <em>flowmodelpath</em> and <em>markovmodelseed</em>
attributes on the <strong>traffic</strong> action.</li>
<li>In a <strong>flow</strong> action, a Markov model can be used to configure the stream
creation process, i.e., the frequency with which new TCP streams should
be created. The Markov model specifies inter-stream delay distributions.
This model is configured with the <em>streammodelpath</em> and <em>markovmodelseed</em>
attributes on the <strong>flow</strong> action. It can also be configured on a
<strong>traffic</strong> action in order to apply the model to all flows generated by
the action.</li>
<li>In a <strong>stream</strong> action, a Markov model can be used to configure the packet
creation process on the associated TCP stream, i.e., the frequency with
which packets should be created. The Markov model specifies inter-packet
delay distributions. This model is configured with the <em>packetmodelpath</em>
and <em>markovmodelseed</em> attributes on the <strong>stream</strong> action. It can also be
configured on <strong>traffic</strong> or <strong>flow</strong> actions in order to apply the model
to all TCP streams generated the associated flows.</li>
</ul>
<p>More information about how to set up a Markov model in your TGen configuration
file can be found in the <a href="tgen/TGen-Options.html">doc/TGen-Options.md</a> file.</p>
<p>The remainder of this document explains the Markov model file format that TGen
supports, and provides examples of how to generate Markov models that will
pass TGen's Markov model validation.</p>
<h1 id="file-format-and-structure"><a class="header" href="#file-format-and-structure">File Format and Structure</a></h1>
<p>As with the config file, TGen uses the <code>graphml</code> file format to represent
Markov models. As we explain the structure supported by TGen, we provide
examples of generating the corresponding <code>graphml</code> elements and atrributes
using <code>python3</code> and the <code>networkx</code> python3 module (installing the TGenTools
toolkit will install the networkx module).</p>
<p>Models are constructed as directed graphs:</p>
<pre><code class="language-python">G = networkx.DiGraph()
</code></pre>
<p>Generally, the Markov model specifies a set of Markov model states and a set
of transitions between pairs of states. Each state is also associated with a
set of observations, and a set of emissions between states and observations.</p>
<h3 id="vertices-markov-model-states-and-observations"><a class="header" href="#vertices-markov-model-states-and-observations">Vertices: Markov model states and observations</a></h3>
<p>Vertices in the graph can either be Markov model &quot;states&quot; or &quot;observations&quot;,
and the type is encoded in the graph using the <em>type</em> attribute on the graph
node. Each vertex must specify a <em>type</em> and a <em>name</em>. The vertex <em>id</em> is
required and must be unique but are otherwise not used by TGen.</p>
<pre><code class="language-python">G.add_node('s0', type=&quot;state&quot;, name='start')
G.add_node('s1', type=&quot;state&quot;, name='anything_you_want')
</code></pre>
<p>The graph must contain one and only one vertex of <em>type</em> <code>state</code> whose <em>name</em>
is <code>start</code>. This instructs TGen in which state the Marov model begins. The
<em>name</em> of the other vertices of <em>type</em> <code>state</code> are insignificant and can be
set to any string.</p>
<pre><code class="language-python">G.add_node('o1', type=&quot;observation&quot;, name='+')
G.add_node('o2', type=&quot;observation&quot;, name='-')
</code></pre>
<p>Vertices of <em>type</em> <code>observation</code> must set one of the following as the <em>name</em>,
which encodes the action to be taken upon reaching a particular vertex. Valid
<em>name</em> strings are:</p>
<ul>
<li><code>+</code>: Generate a packet from client to server (for packet models) or a new
stream (for stream models)</li>
<li><code>-</code>: Generate a packet from server to client (for packet models) or a new
stream (for stream models)</li>
<li><code>F</code>: Stop generating new packets (for packet models) or new streams
(for stream models)</li>
</ul>
<p>For stream models, there is no difference between <code>+</code> and <code>-</code>: you can simply
use <code>+</code> to indicate new stream creation on stream models.</p>
<h3 id="edges-markov-model-state-transitions-and-emissions"><a class="header" href="#edges-markov-model-state-transitions-and-emissions">Edges: Markov model state transitions and emissions</a></h3>
<p>Edges in the graph can either be Markov model &quot;transitions&quot; or &quot;emissions&quot;,
and the type is encoded in the graph using the <em>type</em> attribute on the graph
edge. Each edge must specify a <em>type</em> and a <em>weight</em>. The source and target
vertex <em>id</em> must match those that were defined when creating the vertices.</p>
<pre><code class="language-python">G.add_edge('s0', 's1', type='transition', weight=1.0)
G.add_edge('s1', 's1', type='transition', weight=1.0)
</code></pre>
<p>Edges of <em>type</em> <code>transition</code> instruct TGen how to move between pairs of
vertices of <em>type</em> <code>state</code>. For vertices of <em>type</em> <code>state</code> with multiple
outgoing edges of <em>type</em> <code>transition</code>, TGen randomly selects one outgoing
edge according to the weighted probabilities (each edge's probability is
computed by dividing its weight by the sum of the weights of all outgoing
<code>transition</code> edges from the same <code>state</code> vertex).</p>
<pre><code class="language-python">G.add_edge('s1', 'o1', type='emission', weight=0.5, distribution='normal', param_location=5000000, param_scale=1000000)
G.add_edge('s1', 'o2', type='emission', weight=0.5, distribution='exponential', param_rate=0.001)
</code></pre>
<p>Whenever TGen moves between states, there is an associated event observation.
Edges of <em>type</em> <code>emission</code> instruct TGen how to move between vertices of
<em>type</em> <code>state</code> and vertices of <em>type</em> <code>observation</code>. For vertices of <em>type</em>
<code>state</code> with multiple outgoing edges of <em>type</em> <code>emission</code>, TGen randomly
selects one outgoing edge according to the weighted probabilities (each edge's
probability is computed by dividing its weight by the sum of the weights of
all outgoing <code>emission</code> edges from the same <code>state</code> vertex).</p>
<p>Once an <code>emission</code> edge has been selected, the <code>observation</code> vertex
connected by the edge instructs TGen which type of action to take.
Additionally, each <code>emission</code> edge must specify the <code>distribution</code> attribute
and the associated parameters for that distribution. These distributions encode
the <strong>time delay in microseconds</strong> that TGen should create after the observation
before transitioning to the next state.</p>
<p>The following delay distributions are currently supported (more can be added
as the need arises):</p>
<ul>
<li><code>uniform</code>: a uniform distribution requires the attributes
<code>param_low</code> (a) and <code>param_high</code> (b) such that a &lt;= b to generate
values uniformly in the range [a, b]</li>
<li><code>normal</code>: a normal distribution requires the attributes
<code>param_location</code> (mu) and <code>param_scale</code> (sigma)</li>
<li><code>lognormal</code>: a lognormal distribution requires the attributes
<code>param_location</code> (mu) and <code>param_scale</code> (sigma)</li>
<li><code>exponential</code>: an exponential distribution requires the attribute
<code>param_rate</code> (lamda)</li>
<li><code>pareto</code>: a Pareto distribution requires the attributes
<code>param_scale</code> (xm) and <code>param_shape</code> (alpha)</li>
</ul>
<p>A final graph can be written to a file using:</p>
<pre><code class="language-python">networkx.write_graphml(G, 'sample.mmodel.graphml')
</code></pre>
<h1 id="examples"><a class="header" href="#examples">Examples</a></h1>
<p>Below is a full example of code provided above. Another example script, which
we use to generate our internal default packet and stream models, can be found
in the repository at <a href="tgen/../tools/scripts/generate_mmodel_graphml.py">tools/scripts/generate_mmodel_graphml.py</a>.</p>
<pre><code class="language-python">G = networkx.DiGraph()

G.add_node('s0', type=&quot;state&quot;, name='start')
G.add_node('s1', type=&quot;state&quot;, name='anything_you_want')

G.add_node('o1', type=&quot;observation&quot;, name='+')
G.add_node('o2', type=&quot;observation&quot;, name='-')

G.add_edge('s0', 's1', type='transition', weight=1.0)
G.add_edge('s1', 's1', type='transition', weight=1.0)

G.add_edge('s1', 'o1', type='emission', weight=0.5, distribution='normal', param_location=5000000, param_scale=1000000)
G.add_edge('s1', 'o2', type='emission', weight=0.5, distribution='exponential', param_rate=0.001)

networkx.write_graphml(G, 'sample.mmodel.graphml')
</code></pre>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h1 id="tgen-options-attributes"><a class="header" href="#tgen-options-attributes">TGen Options (attributes)</a></h1>
<p>In <a href="tgen/TGen-Overview.html">doc/TGen-Overview.md</a> we provided an overview how we use a graph to configure TGen. You should read and understand that document first. In this document we specify the full set of options (attributes) that can be set on each action (vertex) in the TGen configuration graph.</p>
<h2 id="option-formats"><a class="header" href="#option-formats">Option formats</a></h2>
<p>All attributes are currently stored as strings in graphml. When we specify the attributes, we use the following shorthand to describe the value formats:</p>
<ul>
<li>peer: &lt;ip&gt;:&lt;port&gt;<br />
e.g., 127.0.0.1:9050 or 192.168.1.100:8080</li>
<li>size: &lt;integer&gt; &lt;suffix&gt;<br />
e.g., &quot;5 suffix&quot; (&quot;5&quot; defaults to &quot;5 bytes&quot;) where suffix is case in-sensitive and one of:<br />
b, byte, bytes,<br />
kb, kilobyte, kilobytes,<br />
kib, kibibyte, kibibytes,<br />
mb, megabyte, megabytes,<br />
mib, mebibyte, mebibytes,<br />
gb, gigabyte, gigabytes,<br />
gib, gibibyte, gibibytes,<br />
tb, terabyte, terabytes,<br />
tib, tebibyte, tebibytes</li>
<li>time: &lt;integer&gt; &lt;suffix&gt;<br />
e.g., &quot;60 suffix&quot; (&quot;60&quot; defaults to &quot;60 seconds&quot;) where suffix is case in-sensitive and one of:<br />
nanosecond, nanoseconds, nsec, nsecs, ns,<br />
microsecond, microseconds, usec, usecs, us,<br />
millisecond, milliseconds, msec, msecs, ms,<br />
second, seconds, sec, secs, s,<br />
minute, minutes, min, mins, m,<br />
hour, hours, hr, hrs, h</li>
</ul>
<h2 id="start-options"><a class="header" href="#start-options">Start options</a></h2>
<p>Acceptable attributes for the <strong>start</strong> action:</p>
<table><thead><tr><th>Name</th><th>Format</th><th>Example</th><th>Description</th></tr></thead><tbody>
<tr><td><em>serverport</em></td><td>&lt;integer&gt;</td><td>8080</td><td>The local port that will be opened to listen for other tgen connections. Set this value if your tgen instance should act as a server for other tgen client requests.</td></tr>
<tr><td><em>time</em></td><td>&lt;time&gt;</td><td>1 second</td><td>The time that tgen should delay before starting a walk through the action graph. If not given, tgen will start immediately upon process initialization.</td></tr>
<tr><td><em>heartbeat</em></td><td>&lt;time&gt;</td><td>1 second</td><td>The time between which heartbeat status messages are logged at 'message' level. A default of 1 second is used if <em>heartbeat</em> is not set. The heartbeat message is disabled if <em>heartbeat</em> is set to 0.</td></tr>
<tr><td><em>loglevel</em></td><td>&lt;string&gt;</td><td>info</td><td>The level above which tgen log messages will be filtered and not shown or logged. Valid values in increasing order are: 'error', 'critical', 'message', 'info', and 'debug'. The default value if <em>loglevel</em> is not set is 'message'.</td></tr>
<tr><td><em>*</em></td><td>*</td><td>*</td><td>All options for the <strong>traffic</strong>, <strong>flow</strong>, and <strong>stream</strong> actions specified below can also be set in the <strong>start</strong> action. Any such options that are specified in the <strong>start</strong> action are treated as the global default option for all such actions. You can then override this global default by also setting the option in any individual action.</td></tr>
</tbody></table>
<h2 id="traffic-options"><a class="header" href="#traffic-options">Traffic options</a></h2>
<p>Acceptable attributes for the <strong>traffic</strong> action:</p>
<table><thead><tr><th>Name</th><th>Format</th><th>Example</th><th>Description</th></tr></thead><tbody>
<tr><td><em>flowmodelpath</em></td><td>&lt;filepath&gt;</td><td>~/flows.graphml</td><td>The Markov model to use to generate flows. If unspecified, tgen will use a default Markov model that repeatedly generates flows in both directions at a constant rate and with no inter-flow delay.</td></tr>
<tr><td>*</td><td>*</td><td>*</td><td>All options for the <strong>flow</strong> and <strong>stream</strong> actions specified below can also be set in the <strong>traffic</strong> action. Any flow or stream options that are specified in the traffic action will be passed through to all flows and streams generated with the flow and stream Markov models specified for this traffic action (and will therefore override options with the same name that were specified in the start action).</td></tr>
</tbody></table>
<h2 id="flow-options"><a class="header" href="#flow-options">Flow options</a></h2>
<p>Acceptable attributes for the <strong>flow</strong> action:</p>
<table><thead><tr><th>Name</th><th>Format</th><th>Example</th><th>Description</th></tr></thead><tbody>
<tr><td><em>streammodelpath</em></td><td>&lt;filepath&gt;</td><td>~/streams.graphml</td><td>The Markov model to use to generate streams in this flow. If unspecified, tgen will use a default Markov model that repeatedly generates streams in both directions at a constant rate and with no inter-stream delay.</td></tr>
<tr><td>*</td><td>*</td><td>*</td><td>All options for the <strong>stream</strong> action specified below can also be set in the <strong>flow</strong> action. Any stream options that are specified in the flow action will be passed through to all streams generated with the stream Markov model specified for this flow (and will therefore override options with the same name that were specified in the start action).</td></tr>
</tbody></table>
<h2 id="stream-options"><a class="header" href="#stream-options">Stream options</a></h2>
<p>Acceptable attributes for the <strong>stream</strong> action:</p>
<table><thead><tr><th>Name</th><th>Format</th><th>Example</th><th>Description</th></tr></thead><tbody>
<tr><td><em>packetmodelpath</em></td><td>&lt;filepath&gt;</td><td>~/packets.graphml</td><td>The Markov model to use to generate packets in this stream. If unspecified, tgen will use an internal default Markov model with no end state that causes tgen to continously generates packets in both directions with no inter-packet delay.</td></tr>
<tr><td><em>packetmodelmode</em></td><td>&lt;string&gt;</td><td>'path' or 'graphml'</td><td>Sets the mode that tgen uses to send the packet Markov model to the server. If unset or set to 'graphml', the tgen client will load the model locally and send a string representation of the model formatted as graphml during the stream handshake. If set to 'path', the client will send the path given in the <em>packetmodelpath</em> attribute to the server, and the server will attempt to load the model at that same path (the server must already have a copy of the model).</td></tr>
<tr><td><em>markovmodelseed</em></td><td>&lt;integer&gt;</td><td>12345</td><td>The seed that will be used to initialize a pseudorandom number generator (prng) that will generate seeds for all Markov models created for this action. If unspecified, tgen initializes the prng using a seed generated by a global prng that was randomly seeded.</td></tr>
<tr><td><em>peers</em></td><td>&lt;peer&gt;,...</td><td>10.0.0.1,...</td><td><strong>Required:</strong> a comma-separated list of peers to use for this <strong>stream</strong>. The <em>peers</em> attribute is <strong>required</strong> unless a <em>peers</em> attribute is specified in the <strong>start</strong> action. A peer will be selected at random from this list, or at random from the <strong>start</strong> action list if this attribute is not specified.</td></tr>
<tr><td><em>socksproxy</em></td><td>&lt;peer&gt;,...</td><td>127.0.0.1:9050</td><td>A comma-separated list of peers to use as proxy servers through which all connections to other tgen peers will be made. If not given, tgen will connect to the peer directly unless this option is set in the <strong>start</strong> action.</td></tr>
<tr><td><em>socksusername</em></td><td>&lt;string&gt;</td><td>myuser</td><td>The SOCKS username that we should send to the SOCKS proxy during the SOCKS handshake for this stream. This option is ignored unless <em>socksproxy</em> is also set in either this <strong>stream</strong> action or in the <strong>start</strong> action.</td></tr>
<tr><td><em>sockspassword</em></td><td>&lt;string&gt;</td><td>mypass</td><td>The SOCKS password that we should send to the SOCKS proxy during the SOCKS handshake for this stream. This option is ignored unless <em>socksproxy</em> is also set in either this <strong>stream</strong> action or in the <strong>start</strong> action.</td></tr>
<tr><td><em>socksauthseed</em></td><td>&lt;integer&gt;</td><td>12345</td><td>If set, the seed that will be used to initialize a pseudorandom number generator (prng) that will generate random <em>socksusername</em> and <em>sockspassword</em> strings that we send to the SOCKS proxy during the SOCKS handshake. If set on a <strong>stream</strong> action, random strings will be generated for each stream; otherwise, random strings will be generated for each <strong>flow</strong>, and all streams generated by a flow will use the same strings as the flow that generated them. This option is ignored unless <em>socksproxy</em> is also set, and overrides any <em>socksusername</em> and <em>sockspassword</em> options that were set.</td></tr>
<tr><td><em>sendsize</em></td><td>&lt;size&gt;</td><td>5 KiB</td><td>The amount of payload data to send from the client to the server after completing the initial handshake. If not set, then the client will continue sending data until it reaches the end state in the Markov model. If set to a positive value, the Markov model will be reset and repeated as necessary until the <em>sendsize</em> is reached. If set to 0, the client will send no payload data following the handshake. To send an infinite stream, either configure a Markov model with no 'F' emissions or don't configure a Markov model (in which case an internal nonstop model will be used).</td></tr>
<tr><td><em>recvsize</em></td><td>&lt;size&gt;</td><td>10 MiB</td><td>This is analagous to the <em>sendsize</em> option, but for payload data received by the client from the server (i.e., payload data sent from the server to the client).</td></tr>
<tr><td><em>timeout</em></td><td>&lt;time&gt;</td><td>2 minutes</td><td>The amount of time since the stream started after which we give up on it. If specified, this stream overrides any <em>timeout</em> attribute that may have been set on the <strong>start</strong> action. If this is set to 0, then an absolute timeout is disabled. If this is not set and is also not set in <strong>start</strong> action, then an absolute timeout is disabled.</td></tr>
<tr><td><em>stallout</em></td><td>&lt;time&gt;</td><td>30 seconds</td><td>The amount of time since bytes were last sent or received for this stream after which we consider this a stalled stream and give up on it. If specified, this stream overrides any <em>stallout</em> attribute that may have been set on the <strong>start</strong> element. If this is set to 0, then a stallout is disabled. If this is not set and is also not set in <strong>start</strong> action, then an internally defined stallout is used instead (currently 30 seconds).</td></tr>
</tbody></table>
<h2 id="pause-options"><a class="header" href="#pause-options">Pause options</a></h2>
<p>Acceptable attributes for the <strong>pause</strong> action:</p>
<table><thead><tr><th>Name</th><th>Format</th><th>Example</th><th>Description</th></tr></thead><tbody>
<tr><td><em>time</em></td><td>&lt;time&gt;,...</td><td>5 seconds,...</td><td>The time or comma-separated list of times that the tgen node should pause before resuming the walk through the action graph. If a list is given, a time from the list will be chosen uniformly at random every time the pause action is encountered while walking the graph.</td></tr>
</tbody></table>
<h2 id="end-options"><a class="header" href="#end-options">End options</a></h2>
<p>Acceptable attributes for the <strong>end</strong> action:</p>
<table><thead><tr><th>Name</th><th>Format</th><th>Example</th><th>Description</th></tr></thead><tbody>
<tr><td><em>time</em></td><td>&lt;time&gt;</td><td>10 minutes</td><td>Stop if this amount of time has passed since tgen started.</td></tr>
<tr><td><em>count</em></td><td>&lt;integer&gt;</td><td>10</td><td>Stop if tgen has completed (successfully or not) this number of streams.</td></tr>
<tr><td><em>sendsize</em></td><td>&lt;size&gt;</td><td>1 GiB</td><td>Stop if this amount of data was sent by the client.</td></tr>
<tr><td><em>recvsize</em></td><td>&lt;size&gt;</td><td>1 GiB</td><td>Stop if this amount of data was received by the client.</td></tr>
</tbody></table>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h1 id="tgen-overview"><a class="header" href="#tgen-overview">TGen Overview</a></h1>
<p>This document explains how to use TGen to generate traffic. It explains how we
use a directed graph to instruct TGen how to generate traffic and outlines the
significance of the vertices, edges, and attributes in the graph. Ultimately,
the <code>graphml</code> file containing the graph structure and attributes acts as the
TGen configuration file.</p>
<p>After reading this document, see <a href="tgen/TGen-Options.html">doc/TGen-Options.md</a>
for a full list of options that can be used in TGen.</p>
<h1 id="action-dependency-graph-format"><a class="header" href="#action-dependency-graph-format">Action-dependency graph format</a></h1>
<p>Graph vertices represent <strong>actions</strong>, and graph edges represent
<strong>dependencies</strong>. Each vertex may contain vertex attributes which specify TGen
<strong>options</strong>. Tgen will walk the directed graph path starting at a <strong>start</strong>
vertex, and execute each action along that path. The actions control the
behavior at each stage.</p>
<h1 id="actions-vertices"><a class="header" href="#actions-vertices">Actions (vertices)</a></h1>
<table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td><strong>start</strong></td><td>The <strong>start action is required</strong> for all tgen graph files, and <strong>only one start action is allowed</strong> per tgen instance.</td></tr>
<tr><td><strong>traffic</strong></td><td>Traffic actions are used to specify how to generate new flows, new streams in each of the new flows, and new packets in each of the new streams.</td></tr>
<tr><td><strong>flow</strong></td><td>Flow actions are used to specify how to generate new streams, and new packets in each of the new streams.</td></tr>
<tr><td><strong>stream</strong></td><td>Stream actions are used to specify how to generate and transfer new packets between two tgen instances.</td></tr>
<tr><td><strong>pause</strong></td><td>Pause actions are used to insert pauses between the execution of transfers. If no time is given, then this action will pause a walk until the vertex has been visited by all incoming edges. More specifically, a pause action without a time is 'activated' when it is first visiting by an incoming edge, and then begins counting visitation by all other incoming edges. Once the 'activated' vertex is visited by all incoming edges, it 'deactivates' and then the walk continues by following each outgoing edge. The pause action acts as a 'barrier'; an example usage would be to start multiple transfers in parallel and wait for them all to finish with a 'pause' before starting the next action.</td></tr>
<tr><td><strong>end</strong></td><td>End actions are used to specify termination conditions for tgen clients; for example, clients can stop after completing a certain number of transfers or transferring a certain amount of data. If any of the configured conditions are met upon arriving at an end action vertex, the tgen node will stop and shutdown.</td></tr>
</tbody></table>
<h1 id="dependencies-edges"><a class="header" href="#dependencies-edges">Dependencies (edges)</a></h1>
<p>Edges direct tgen from one action to the next. tgen will perform the above actions by starting at the start vertex and following the edges through the graph. By default, tgen will follow all outgoing edges from a vertex in parallel, thereby creating <em>multiple concurrent execution paths</em> in the graph.</p>
<p>Each edge may contain a 'weight' attribute with a floating point 'double' value, e.g., <code>weight=&quot;1.0&quot;</code>. While tgen will follow all outgoing edges of a vertex for which no weight is assigned, tgen will choose and follow one and only one edge from the set of weighted outgoing edges of a vertex. A <em>single execution path</em> can be maintained by assigning weights to all outgoing edges of a vertex.</p>
<p>A weighted choice is used to select which weighted outgoing edge of a vertex to follow, based on the sum of weights of all weighted outgoing edges. Therefore, if all weighted outgoing edges have the same weight, the choice will essentially be a uniform random choice.</p>
<p>Be warned that edge weights must be used carefully, especially when combined with the synchronize action. A synchronize action expects that all incoming edges will visit it, which may not be the case if weighted edges were used at some point in a path leading to the synchronize action.</p>
<h1 id="examples-1"><a class="header" href="#examples-1">Examples</a></h1>
<p>An easy way to generate TGen behavior graphs is to use python3 and the networkx python3 module.
The scripts are simple, but capable of generating complex behavior profiles.</p>
<p>Example scripts for generating TGen configuration files can be found in the
repository at <a href="tgen/../tools/scripts/generate_tgen_config.py">tools/scripts/generate_tgen_config.py</a></p>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h1 id="json-db-structure-for-analysis-results"><a class="header" href="#json-db-structure-for-analysis-results">JSON DB Structure for Analysis Results</a></h1>
<p>The <code>tgentools</code> python3 toolkit can be run in <code>parse</code> mode to parse a set of
tgen log files. It writes useful statistics to a json file.</p>
<p>This document describes the structure of the json database file that gets exported
when running the <code>tgentools</code> python3 toolkit in <code>parse</code> mode.</p>
<p>The structure is given here with variable keys marked as such.</p>
<pre><code>{
  &quot;data&quot;: { # generic keyword
    &quot;phantomtrain&quot;: { # nickname of the OnionPerf client, hostname if not set
      &quot;measurement_ip&quot; : &quot;192.168.1.1&quot;, # public-facing IP address of the machine used for the measurements
      &quot;tgen&quot;: { # to indicate data from TGen
        &quot;transfers&quot;: { # the records for transfers TGen attempted
          &quot;transfer1m:1&quot;: { # the id of a single transfer
            &quot;elapsed_seconds&quot;: { # timing for various steps in transfer, in seconds
              &quot;checksum&quot;: 0.0, # step 12 if using a proxy, else step 8 (initial GET/PUT)
              &quot;command&quot;: 0.319006, # step 7 if using a proxy, else step 3 (initial GET/PUT)
              &quot;first_byte&quot;: 0.0, # step 9 if using a proxy, else step 5 (initial GET/PUT)
              &quot;last_byte&quot;: 0.0, # step 11 if using a proxy, else step 7 (initial GET/PUT)
              &quot;payload_progress&quot;: { # step 10 if using a proxy, else step 6 (initial GET/PUT)
                &quot;0.0&quot;: 0.0, # percent of payload completed : seconds to complete it
                &quot;0.1&quot;: 0.0,
                &quot;0.2&quot;: 0.0,
                &quot;0.3&quot;: 0.0,
                &quot;0.4&quot;: 0.0,
                &quot;0.5&quot;: 0.0,
                &quot;0.6&quot;: 0.0,
                &quot;0.7&quot;: 0.0,
                &quot;0.8&quot;: 0.0,
                &quot;0.9&quot;: 0.0,
                &quot;1.0&quot;: 0.0
              },
              &quot;proxy_choice&quot;: 0.000233, # step 4 if using a proxy, else absent
              &quot;proxy_init&quot;: 0.000151, # step 3 if using a proxy, else absent
              &quot;proxy_request&quot;: 0.010959, # step 5 if using a proxy, else absent
              &quot;proxy_response&quot;: 0.318873, # step 6 if using a proxy, else absent
              &quot;response&quot;: 0.0, # step 8 if using a proxy, else step 4 (initial GET/PUT)
              &quot;socket_connect&quot;: 0.000115, # step 2
              &quot;socket_create&quot;: 2e-06 # step 1
            },
            &quot;endpoint_local&quot;: &quot;localhost:127.0.0.1:45416&quot;, # tgen client socket name:ip:port
            &quot;endpoint_proxy&quot;: &quot;localhost:127.0.0.1:27942&quot;, # proxy socket name:ip:port, if present
            &quot;endpoint_remote&quot;: &quot;server1.peach-hosting.com:216.17.99.183:6666&quot;, # tgen server hostname:ip:port
            &quot;error_code&quot;: &quot;READ&quot;, # 'NONE' or a code to indicate the type of error
            &quot;filesize_bytes&quot;: 1048576, # size of the transfer payload
            &quot;hostname_local&quot;: &quot;puntaburros.amerinoc.com&quot;, # client machine hostname
            &quot;hostname_remote&quot;: &quot;(null)&quot;, # server machine hostname
            &quot;is_commander&quot;: true, # true if client (initiated the transfer), else false
            &quot;is_complete&quot;: true, # if the transfer finished, no matter the error state
            &quot;is_error&quot;: true, # if there was an error in the transfer
            &quot;is_success&quot;: false, # if the transfer completed and checksum passed
            &quot;method&quot;: &quot;GET&quot;, # transfer method (GET,PUT)
            &quot;payload_bytes_status&quot;: 0, # cumulative number of payload bytes received
            &quot;total_bytes_read&quot;: 0, # total bytes read from the socket
            &quot;total_bytes_write&quot;: 50, # total written to the socket
            &quot;transfer_id&quot;: &quot;transfer1m:1&quot;, # the id of this transfer, unique to this run of OnionPerf
            &quot;unix_ts_end&quot;: 1456699868.006196, # initial start time of the transfer
            &quot;unix_ts_start&quot;: 1456699868.006196 # final end time of the transfer
          },
        },
        &quot;transfers_summary&quot;: { # summary stats of all transfers in the 'transfers' section
          &quot;errors&quot;: {
            &quot;PROXY&quot;: { # PROXY type errors
              &quot;1456654221&quot;: [ # the second at which the error occurred
                51200 # transfer filesizes that had errors, one entry for each error during this second
              ],
            },
            &quot;READ&quot;: { # READ type errors
              &quot;1456618782&quot;: [ # second at which the error occurred
                51200 # transfer filesize, one for each error at this time
              ],
            },
          &quot;time_to_first_byte&quot;: { # time to receive the first byte of the payload
            &quot;51200&quot;: { # file size
              &quot;1456707932&quot;: [ # the second at which the transfer completed
                0.36213199999999995 # time to first byte, in seconds
              ],
            },
          },
          &quot;time_to_last_byte&quot;: { # time to receive the last byte of the payload
            &quot;51200&quot;: { # file size
              &quot;1456707932&quot;: [ # the second at which the transfer completed
                0.6602399999999999 # time to last byte, in seconds
              ],
            }
          }
        },
        &quot;heartbeats&quot;: { # summary info from tgen heartbeat messages
          &quot;bytes-read&quot;: { # the count of bytes received from kernel
            &quot;1456707932&quot;: [ # the second at which the info was obtained
              1534 # the counted value
            ],
          },
          &quot;bytes-written&quot;: { # the count of bytes sent to kernel
            &quot;1456707932&quot;: [ # the second at which the info was obtained
              1534 # the counted value
            ],
          },
          &quot;streams-created&quot;: { # the count of the number of streams created since previous heartbeat message
            &quot;1456707932&quot;: [ # the second at which the info was obtained
              1 # the counted value
            ],
          },
          &quot;streams-succeeded&quot;: { # the count of the number of streams succeeded since previous heartbeat message
            &quot;1456707932&quot;: [ # the second at which the info was obtained
              1 # the counted value
            ],
          },
          &quot;streams-failed&quot;: { # the count of the number of streams failed since previous heartbeat message
            &quot;1456707932&quot;: [ # the second at which the info was obtained
              1 # the counted value
            ],
          },
          &quot;total-streams-created&quot;: { # the count of the cumulative number of streams created
            &quot;1456707932&quot;: [ # the second at which the info was obtained
              1 # the counted value
            ],
          },
          &quot;total-streams-succeeded&quot;: { # the count of the cumulative number of streams succeeded
            &quot;1456707932&quot;: [ # the second at which the info was obtained
              1 # the counted value
            ],
          },
          &quot;total-streams-failed&quot;: { # the count of the cumulative number of streams failed
            &quot;1456707932&quot;: [ # the second at which the info was obtained
              1 # the counted value
            ],
          },
          &quot;total-streams-pending&quot;: { # the count of the cumulative number of streams created but not yet completed
            &quot;1456707932&quot;: [ # the second at which the info was obtained
              1 # the counted value
            ],
          },
          # ... the stream counters are repeated for flows and traffics
        },
      },
    }
  }
}
</code></pre>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h1 id="tornettools"><a class="header" href="#tornettools">tornettools</a></h1>
<p><img src="https://github.com/shadow/tornettools/workflows/Build/badge.svg" alt="" /></p>
<p>tornettools is a utility to guide you through the Tor network
experimentation process using Shadow, by assisting with the
following experimentation steps:</p>
<ul>
<li><strong>stage</strong>:     Process Tor metrics data for staging network generation</li>
<li><strong>generate</strong>:  Generate TorNet network configurations</li>
<li><strong>simulate</strong>:  Run a TorNet simulation in Shadow</li>
<li><strong>parse</strong>:     Parse useful data from simulation log files</li>
<li><strong>plot</strong>:      Plot previously parsed data to visualize results</li>
<li><strong>archive</strong>:   Cleanup and compress Shadow simulation data</li>
</ul>
<p>The configuration files that are generated can be run in the
<a href="https://github.com/shadow/shadow">Shadow network simulator</a>;
<a href="https://crysp.uwaterloo.ca/software/netmirage">NetMirage</a>
and
<a href="https://gitweb.torproject.org/chutney.git">Chutney</a>
may eventually support the files generated with this tool.</p>
<p>The generated networks include the use of
<a href="https://github.com/shadow/tgen">TGen</a>
for the generation of realistic background traffic, and
<a href="https://github.com/shadow/oniontrace">OnionTrace</a>
for the collection of information from Tor throughout an experiment.</p>
<h3 id="setup-is-easy-with-virtualenv-and-pip"><a class="header" href="#setup-is-easy-with-virtualenv-and-pip">setup is easy with virtualenv and pip</a></h3>
<pre><code>python3 -m venv toolsenv
source toolsenv/bin/activate
pip install -r requirements.txt
pip install -I .
</code></pre>
<h3 id="read-the-help-menus"><a class="header" href="#read-the-help-menus">read the help menus</a></h3>
<pre><code>tornettools -h
tornettools stage -h
tornettools generate -h
tornettools simulate -h
tornettools parse -h
tornettools plot -h
tornettools archive -h
</code></pre>
<h3 id="grab-the-data-we-need"><a class="header" href="#grab-the-data-we-need">grab the data we need</a></h3>
<pre><code>wget https://collector.torproject.org/archive/relay-descriptors/consensuses/consensuses-2020-11.tar.xz
wget https://collector.torproject.org/archive/relay-descriptors/server-descriptors/server-descriptors-2020-11.tar.xz
wget https://metrics.torproject.org/userstats-relay-country.csv
wget https://collector.torproject.org/archive/onionperf/onionperf-2020-11.tar.xz
wget -O bandwidth-2020-11.csv &quot;https://metrics.torproject.org/bandwidth.csv?start=2020-11-01&amp;end=2020-11-30&quot;
</code></pre>
<h3 id="extract"><a class="header" href="#extract">extract</a></h3>
<pre><code>tar xaf consensuses-2020-11.tar.xz
tar xaf server-descriptors-2020-11.tar.xz
tar xaf onionperf-2020-11.tar.xz
</code></pre>
<h3 id="we-also-utilize-privcount-tor-traffic-model-measurements"><a class="header" href="#we-also-utilize-privcount-tor-traffic-model-measurements">we also utilize privcount Tor traffic model measurements</a></h3>
<pre><code>git clone https://github.com/tmodel-ccs2018/tmodel-ccs2018.github.io.git
</code></pre>
<h3 id="we-also-need-tor"><a class="header" href="#we-also-need-tor">we also need tor</a></h3>
<pre><code>sudo apt-get install openssl libssl-dev libevent-dev build-essential automake zlib1g zlib1g-dev
git clone https://git.torproject.org/tor.git
cd tor
./autogen.sh
./configure --disable-asciidoc --disable-unittests --disable-manpage --disable-html-manual
make
cd ..
</code></pre>
<h3 id="in-order-to-generate-we-need-a-tor-and-tor-gencert-binaries-to-generate-relay-keys"><a class="header" href="#in-order-to-generate-we-need-a-tor-and-tor-gencert-binaries-to-generate-relay-keys">in order to generate, we need a tor and tor-gencert binaries (to generate relay keys)</a></h3>
<pre><code>export PATH=${PATH}:`pwd`/tor/src/core/or:`pwd`/tor/src/app:`pwd`/tor/src/tools
</code></pre>
<h3 id="stage-first-process-relay-and-user-info"><a class="header" href="#stage-first-process-relay-and-user-info">stage first, process relay and user info</a></h3>
<pre><code>tornettools stage \
    consensuses-2020-11 \
    server-descriptors-2020-11 \
    userstats-relay-country.csv \
    --onionperf_data_path onionperf-2020-11 \
    --bandwidth_data_path bandwidth-2020-11.csv \
    --geoip_path tor/src/config/geoip
</code></pre>
<h3 id="now-we-can-used-the-staged-files-to-generate-many-times"><a class="header" href="#now-we-can-used-the-staged-files-to-generate-many-times">now we can used the staged files to generate many times</a></h3>
<p>For example, use '--network_scale 0.01' to generate a private Tor network at '1%' the scale of public Tor:</p>
<pre><code>tornettools generate \
    relayinfo_staging_2020-11-01--2020-12-01.json \
    userinfo_staging_2020-11-01--2020-12-01.json \
    tmodel-ccs2018.github.io \
    --network_scale 0.01 \
    --prefix tornet-0.01
</code></pre>
<h3 id="now-you-can-run-a-simulation-and-process-the-results"><a class="header" href="#now-you-can-run-a-simulation-and-process-the-results">now you can run a simulation and process the results</a></h3>
<p>Make sure you have already installed <a href="https://github.com/shadow/shadow">shadow</a>, <a href="https://github.com/shadow/tgen">tgen</a>, and <a href="https://github.com/shadow/oniontrace">oniontrace</a>.</p>
<p>Note that simulating a '1%' Tor network for 60 simulation minutes can take as much as 30GiB of RAM.</p>
<pre><code>tornettools simulate tornet-0.01
tornettools parse tornet-0.01
tornettools plot \
    tornet-0.01 \
    --tor_metrics_path tor_metrics_2020-11-01--2020-11-30.json \
    --prefix pdfs
tornettools archive tornet-0.01
</code></pre>
<p>Performance metrics are plotted in the graph files in the pdfs directory.</p>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="oniontrace"><a class="header" href="#oniontrace">OnionTrace</a></h2>
<p><img src="https://github.com/shadow/oniontrace/workflows/Builds/badge.svg" alt="" /></p>
<p>This program records and plays back Tor circuit building and stream assignment.
It can also register for several asynchronous Tor events and logs the events
as they are received from Tor over time.</p>
<h2 id="setup-1"><a class="header" href="#setup-1">Setup</a></h2>
<p>Dependencies in Fedora/RedHat:</p>
<pre><code>sudo yum install cmake glib2 glib2-devel
</code></pre>
<p>Dependencies in Ubuntu/Debian:</p>
<pre><code>sudo apt-get install cmake libglib2.0-0 libglib2.0-dev
</code></pre>
<p>Build with a custom install prefix:</p>
<pre><code>mkdir build &amp;&amp; cd build
cmake .. -DCMAKE_INSTALL_PREFIX=/home/$USER/.local
make
</code></pre>
<p>Optionally install to the prefix:</p>
<pre><code>make install
</code></pre>
<h2 id="usage-1"><a class="header" href="#usage-1">Usage</a></h2>
<p>oniontrace arguments should be configured as follows:
arguments=&quot;oniontrace key=value ...&quot;</p>
<p>The valid keys and the type of the valid values are listed below, along with
any defaults. The format is:<br />
+ <code>key</code>:ValueType (default=<code>val</code>) [Mode=<code>ValidMode</code>] - explanation</p>
<p>Specifying the run mode is <strong>optional</strong>, the default mode is <code>log</code>:</p>
<ul>
<li><code>Mode</code>:String (default=<code>log</code>) [Mode=<code>record</code>,<code>play</code>,<code>log</code>]<br />
Valid values for the running mode are <code>record</code>, <code>play</code>, and <code>log</code>.<br />
<code>record</code> mode records circuit creation and stream assignment schedules.<br />
<code>play</code> mode creates circuits and assigns streams according to a<br />
schedule as previously recorded with <code>record</code> mode.
<code>log</code> mode registers for async events and logs them to stdout as they occur.</li>
</ul>
<p>The following are <strong>required</strong> arguments (default values do not exist):</p>
<ul>
<li><code>TorControlPort</code>:Integer [Mode=<code>record</code>,<code>play</code>,<code>log</code>]<br />
The Tor Control server port, set in the torrc file of the Tor instance that<br />
you want to trace.</li>
</ul>
<p>The following are <strong>optional</strong> arguments (default values exist):</p>
<ul>
<li>
<p><code>LogLevel</code>:String (default=<code>info</code>) [Mode=<code>record</code>,<code>play</code>,<code>log</code>]<br />
The log level to use while running oniontrace. Valid values are:<br />
<code>debug</code> &gt; <code>info</code> &gt; <code>message</code> &gt; <code>warning</code><br />
Messages logged at a higher level than the one configured will be filtered.</p>
</li>
<li>
<p><code>TraceFile</code>:String (default=<code>oniontrace.csv</code>) [Mode=<code>record</code>,<code>play</code>]<br />
The filename to write the trace when in <code>record</code> mode, or read a previously<br />
recorded trace when in <code>play</code> mode.</p>
</li>
<li>
<p><code>RunTime</code>:Integer (default=<code>0</code>) [Mode=<code>record</code>,<code>play</code>]<br />
If positive, OnionTrace will stop running after the number of seconds<br />
specified in this value. In <code>record</code> mode, this has the effect of recording<br />
all circuits that are being tracked even if those circuits have not yet<br />
been closed by Tor.</p>
</li>
<li>
<p><code>Events</code>:String (default=<code>BW</code>) [Mode=<code>log</code>]<br />
The asynchronous Tor events for which we should listen and log when<br />
we receive them from Tor. The value string should be a comma-delimited list<br />
of events, e.g., 'BW,CIRC,STREAM'. See Section 4.1 of the<br />
'Tor control protocol' specification for a full list of acceptable events.<br />
(https://gitweb.torproject.org/torspec.git/tree/control-spec.txt)</p>
</li>
</ul>
<h2 id="tor-changes-required-for-record-mode"><a class="header" href="#tor-changes-required-for-record-mode">Tor Changes Required for record Mode</a></h2>
<p>In order for the <code>record</code> mode to work correctly, we need Tor to export the
socks username in all stream control events. That will allow us to keep the
the same streams on the correct circuits when using <code>playback</code> mode to play
back a recorded trace file.</p>
<p>If the original stream control event is this:</p>
<pre><code>650 STREAM 21 NEW 0 11.0.0.6:18080 SOURCE_ADDR=127.0.0.1:21437
</code></pre>
<p>We need to change Tor so that it outputs events like:</p>
<pre><code>650 STREAM 21 NEW 0 11.0.0.6:18080 SOURCE_ADDR=127.0.0.1:21437 USERNAME=MYUSER
</code></pre>
<p>Where <code>MYUSER</code> is the SOCKS username in use to tie that stream to a circuit.
Here is a patch that was created to do this for <code>tor-0.3.5.8</code>, which may help
you understand how to change a newer version of Tor to export the correct info.</p>
<pre><code>diff --git a/src/feature/control/control.c b/src/feature/control/control.c
index cc7ecff2f..fac51eb38 100644
--- a/src/feature/control/control.c
+++ b/src/feature/control/control.c
@@ -5904,16 +5904,28 @@ control_event_stream_status(entry_connection_t *conn, stream_status_event_t tp,
       purpose = &quot; PURPOSE=USER&quot;;
   }
 
+  /* send socks username along with stream events. */
+  char user[64];
+  int do_user = (conn-&gt;socks_request &amp;&amp; conn-&gt;socks_request-&gt;username) ? 1 : 0;
+
+  if(do_user) {
+    char* u_null_term = tor_memdup_nulterm(conn-&gt;socks_request-&gt;username,
+        conn-&gt;socks_request-&gt;usernamelen);
+    tor_snprintf(user, 64, &quot; USERNAME=%s&quot;, u_null_term);
+    free(u_null_term);
+  }
+
   circ = circuit_get_by_edge_conn(ENTRY_TO_EDGE_CONN(conn));
   if (circ &amp;&amp; CIRCUIT_IS_ORIGIN(circ))
     origin_circ = TO_ORIGIN_CIRCUIT(circ);
   send_control_event(EVENT_STREAM_STATUS,
-                        &quot;650 STREAM %&quot;PRIu64&quot; %s %lu %s%s%s%s\r\n&quot;,
+                        &quot;650 STREAM %&quot;PRIu64&quot; %s %lu %s%s%s%s%s\r\n&quot;,
                      (ENTRY_TO_CONN(conn)-&gt;global_identifier),
                      status,
                         origin_circ?
                            (unsigned long)origin_circ-&gt;global_identifier : 0ul,
-                        buf, reason_buf, addrport_buf, purpose);
+                        buf, reason_buf, addrport_buf, purpose,
+                        do_user ? user : &quot;&quot;);
 
   /* XXX need to specify its intended exit, etc? */
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
